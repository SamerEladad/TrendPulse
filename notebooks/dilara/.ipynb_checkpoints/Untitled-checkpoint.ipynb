{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc7aaf-c98a-46f8-9391-f47fe94a9e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Um eine LLM (Large Language Model) zu erstellen, gibt es einige Schritte, die du beachten solltest. Hier sind einige Empfehlungen:\n",
    "\n",
    "1. **Modellauswahl**: W√§hle ein geeignetes Open-Source-Large-Language-Model aus. Die Community hat viele Rankings erstellt, die verschiedene Modelle vergleichen und bei der Auswahl helfen k√∂nnen¬≥.\n",
    "\n",
    "2. **Kostenbewusstes Routing**: Wenn du mehrere Modelle zur Verf√ºgung hast, kannst du ein kosteneffizientes Routing implementieren. Das bedeutet, dass einfache Anfragen an g√ºnstigere Modelle weitergeleitet werden, w√§hrend komplexere Anfragen an leistungsst√§rkere, aber teurere Modelle geroutet werden. Ein Framework wie \"RouteLLM\" kann dir dabei helfen, diese Entscheidungen zu treffen¬π¬≤.\n",
    "\n",
    "3. **Evaluierung und Feinabstimmung**: Teste dein Modell mit verschiedenen Anfragen und sammle Feedback. Passe die Routing-Strategie basierend auf den Ergebnissen an, um die Kosten zu minimieren und gleichzeitig die Qualit√§t der Antworten zu gew√§hrleisten.\n",
    "\n",
    "Denke daran, dass die genaue Implementierung von deinen spezifischen Anforderungen abh√§ngt. Viel Erfolg beim Erstellen deiner LLM! üöÄ\n",
    "\n",
    "Quelle: Unterhaltung mit Copilot, 7.8.2024\n",
    "(1) Open Source Large Language Models selbst betreiben. https://www.iese.fraunhofer.de/blog/open-source-large-language-models-selbst-betreiben/.\n",
    "(2) RouteLLM: An Open-Source Framework for Cost-Effective LLM Routing. https://lmsys.org/blog/2024-07-01-routellm/.\n",
    "(3) GitHub - lm-sys/RouteLLM: A framework for serving and evaluating LLM .... https://github.com/lm-sys/RouteLLM.\n",
    "(4) undefined. https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard.\n",
    "\n",
    "Nat√ºrlich! Hier ist eine vereinfachte Schritt-f√ºr-Schritt-Anleitung zum Erstellen einer Large Language Model (LLM) mit einem speziellen Datensatz:\n",
    "\n",
    "1. **Modellauswahl**:\n",
    "   - W√§hle ein geeignetes Open-Source-Large-Language-Model aus¬π.\n",
    "   - Achte darauf, dass es unter einer \"gutm√ºtigen\" Lizenz steht (z. B. Apache 2.0).\n",
    "\n",
    "2. **Datensatzvorbereitung**:\n",
    "   - Beschaffe den speziellen Datensatz, den du verwenden m√∂chtest.\n",
    "   - Reinige und strukturiere die Daten, um sie f√ºr das Training vorzubereiten.\n",
    "\n",
    "3. **Training des Modells**:\n",
    "   - Nutze die Trainingsdaten, um das LLM zu trainieren.\n",
    "   - Experimentiere mit Hyperparametern und Trainingsdauer, um optimale Ergebnisse zu erzielen.\n",
    "\n",
    "4. **Feinabstimmung (Fine-Tuning)**:\n",
    "   - Falls n√∂tig, f√ºhre eine Feinabstimmung auf deinem speziellen Datensatz durch¬π.\n",
    "   - Dies verbessert die Modellleistung f√ºr deinen Anwendungsfall.\n",
    "\n",
    "5. **Quantisierung und Performance-Optimierung**:\n",
    "   - Quantisiere das Modell, um es effizienter auf GPUs auszuf√ºhren¬π.\n",
    "   - Verwende ein performantes Backend wie vLLM oder Llama.cpp¬π.\n",
    "\n",
    "6. **Evaluation und Verbesserung**:\n",
    "   - Teste das Modell mit verschiedenen Anfragen und sammle Feedback.\n",
    "   - Passe die Modellarchitektur und Hyperparameter an, um die Qualit√§t zu steigern.\n",
    "\n",
    "Viel Erfolg bei der Erstellung deiner LLM! üöÄ\n",
    "\n",
    "Quelle: Unterhaltung mit Copilot, 7.8.2024\n",
    "(1) Open Source Large Language Models selbst betreiben. https://www.iese.fraunhofer.de/blog/open-source-large-language-models-selbst-betreiben/.\n",
    "(2) Was sind Large Language Models (LLM) ‚Äì Top-Anwendungsf√§lle, Datens√§tze .... https://de.shaip.com/blog/a-guide-large-language-model-llm/.\n",
    "(3) Wie funktionieren LLMs? Ein Blick ins Innere gro√üer Sprachmodelle. https://www.iese.fraunhofer.de/blog/wie-funktionieren-llms/.\n",
    "(4) Ollama CheatSheet: Einstieg in das lokale Ausf√ºhren von LLM mit Ollama. http://anakin.ai/de/blog/ollama-cheatsheet-local-llm/.\n",
    "(5) Vollst√§ndige Anleitung zur Generierung synthetischer Daten f√ºr LLM .... https://www.unite.ai/de/Vollst%C3%A4ndige-Anleitung-zur-Generierung-synthetischer-LLM-Daten/.\n",
    "\n",
    "\n",
    "Die Hyperparameter beim Training von Large Language Models (LLMs) sind entscheidend, um die Modellleistung zu optimieren. Hier sind einige der wichtigsten LLM-Hyperparameter und ihre Auswirkungen auf die Modellausgabe:\n",
    "\n",
    "1. **Modellgr√∂√üe**:\n",
    "   - Die Gr√∂√üe des LLMs beeinflusst seine Leistung. Gr√∂√üere Modelle sind leistungsst√§rker und besser f√ºr komplexe Aufgaben geeignet.\n",
    "   - Allerdings sind gr√∂√üere Modelle teurer, ben√∂tigen mehr Trainingsdaten und Ressourcen und k√∂nnen anf√§lliger f√ºr √úberanpassung sein¬π.\n",
    "\n",
    "2. **Lernrate**:\n",
    "   - Die Lernrate steuert, wie schnell das Modell auf den berechneten Verlust reagiert.\n",
    "   - Eine h√∂here Lernrate beschleunigt das Training, kann aber zu Instabilit√§t und √úberanpassung f√ºhren¬π.\n",
    "\n",
    "3. **Anzahl der versteckten Schichten**:\n",
    "   - Die Anzahl der Schichten beeinflusst die Modellkomplexit√§t und die F√§higkeit zur Repr√§sentation von Informationen¬≥.\n",
    "\n",
    "4. **Dropout-Rate**:\n",
    "   - Dropout ist eine Technik zur Vermeidung von √úberanpassung. Eine h√∂here Dropout-Rate reduziert die Abh√§ngigkeit zwischen Neuronen¬≥.\n",
    "\n",
    "5. **Anzahl der Trainingsiterationen (Epochen)**:\n",
    "   - Die Anzahl der Epochen bestimmt, wie oft das Modell die Trainingsdaten durchl√§uft¬≥.\n",
    "\n",
    "6. **Clustering-Parameter** (bei Clustering-Aufgaben):\n",
    "   - Die Anzahl der Cluster beeinflusst die Gruppierung von Datenpunkten¬≥.\n",
    "\n",
    "Denke daran, dass die optimale Konfiguration von deinem spezifischen Anwendungsfall abh√§ngt. Experimentiere und passe die Hyperparameter entsprechend an! üöÄ\n",
    "\n",
    "Quelle: Unterhaltung mit Copilot, 7.8.2024\n",
    "(1) A Guide to LLM Hyperparameters | Symbl.ai. https://symbl.ai/developers/blog/a-guide-to-llm-hyperparameters/.\n",
    "(2) Parameters, Hyperparameters, Machine Learning | Towards Data Science. https://towardsdatascience.com/parameters-and-hyperparameters-aa609601a9ac.\n",
    "(3) LLM Hyperparameters - LLM Built. https://llmbuilt.com/llm-hyperparameters/.\n",
    "(4) 10 Hyperparameter Tuning Tips for LLM Fine-Tuning. https://llmmodels.org/blog/10-hyperparameter-tuning-tips-for-llm-fine-tuning/.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
