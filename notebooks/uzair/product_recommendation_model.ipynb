{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, auc, accuracy_score, roc_curve, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR, MultiplicativeLR, ExponentialLR\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = 'new_exp'\n",
    "experiment = 'Embedding_without_sub-cat_rating'\n",
    "exp_dir = os.path.join(main_dir, experiment)\n",
    "weights_dir = os.path.join(exp_dir, 'model_weights')\n",
    "log_path = os.path.join(exp_dir, 'Training_log.txt')\n",
    "os.makedirs(weights_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the separated Training Data for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the separated training data into df\n",
    "\n",
    "df = pd.read_excel('Train_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Distribute the entire data in 3 categories for classification.\n",
    "# Class_0 -> (rating= 1-2.5), Class_1 -> (rating = 2.6-4.0), Class_2 -> (rating = 4.1 - 5.0)\n",
    "\n",
    "# Create the int_rating column using a lambda function with three categories of ratings\n",
    "df['int_rating'] = df['ratings'].apply(lambda x: 0 if x <= 2.5 else (1 if x <= 4.0 else 2))\n",
    "# df['int_rating'] = df['ratings'].apply(lambda x: 0 if x <= 4.0 else 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create manual mappings for categorical columns\n",
    "\n",
    "# Mapping products\n",
    "unique_products = df['product'].unique()\n",
    "product_to_index = {product: idx for idx, product in enumerate(unique_products)}\n",
    "df['encoded_product'] = df['product'].map(product_to_index)\n",
    "\n",
    "# Save the product encoding dictionary\n",
    "with open(os.path.join(exp_dir,'product_to_index.pkl'), 'wb') as f:\n",
    "    pickle.dump(product_to_index, f)\n",
    "\n",
    "# Mapping main categories\n",
    "unique_main_categories = df['main_category'].unique()\n",
    "main_category_to_index = {category: idx for idx, category in enumerate(unique_main_categories)}\n",
    "df['encoded_main_category'] = df['main_category'].map(main_category_to_index)\n",
    "\n",
    "# Save the main category encoding dictionary\n",
    "with open(os.path.join(exp_dir,'main_category_to_index.pkl'), 'wb') as f:\n",
    "    pickle.dump(main_category_to_index, f)\n",
    "\n",
    "# Mapping subcategories\n",
    "unique_sub_categories = df['sub_category'].unique()\n",
    "sub_category_to_index = {subcategory: idx for idx, subcategory in enumerate(unique_sub_categories)}\n",
    "df['encoded_sub_category'] = df['sub_category'].map(sub_category_to_index)\n",
    "\n",
    "# Save the subcategory encoding dictionary\n",
    "with open(os.path.join(exp_dir,'sub_category_to_index.pkl'), 'wb') as f:\n",
    "    pickle.dump(sub_category_to_index, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert prices from rupees to USD\n",
    "df['actual_price'] = df['actual_price'] / 83\n",
    "df['discount_price'] = df['discount_price'] / 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(os.path.join(exp_dir, 'Train_Data_3_classes_encoded.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Process the 'link' column if necessary or drop it\n",
    "# df = train_df.drop(columns=['link'])\n",
    "\n",
    "# Step 2: Normalize numerical columns\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "df[['ratings', 'no_of_ratings', 'actual_price', 'discount_price']] = scaler.fit_transform(df[['ratings', 'no_of_ratings', 'actual_price', 'discount_price']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df[['encoded_product', 'encoded_main_category', 'encoded_sub_category', 'ratings', 'no_of_ratings', 'actual_price', 'discount_price']]\n",
    "y = df['int_rating']\n",
    "\n",
    "# Stratified split to maintain the distribution of int_rating across train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Combine features and target back into DataFrames\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_excel(os.path.join(exp_dir,'encoded_train_data.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert training data to PyTorch tensors\n",
    "train_product_ids = torch.tensor(train_df['encoded_product'].values, dtype=torch.long)\n",
    "train_category_ids = torch.tensor(train_df['encoded_main_category'].values, dtype=torch.long)\n",
    "train_subcategory_ids = torch.tensor(train_df['encoded_sub_category'].values, dtype=torch.long)\n",
    "train_ratings = torch.tensor(train_df['ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "train_no_of_ratings = torch.tensor(train_df['no_of_ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "train_actual_price = torch.tensor(train_df['actual_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "train_discount_price = torch.tensor(train_df['discount_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "train_labels = torch.tensor(train_df['int_rating'].values, dtype=torch.long)  # CrossEntropyLoss expects long dtype for labels\n",
    "\n",
    "# Convert validation data to PyTorch tensors\n",
    "val_product_ids = torch.tensor(val_df['encoded_product'].values, dtype=torch.long)\n",
    "val_category_ids = torch.tensor(val_df['encoded_main_category'].values, dtype=torch.long)\n",
    "val_subcategory_ids = torch.tensor(val_df['encoded_sub_category'].values, dtype=torch.long)\n",
    "val_ratings = torch.tensor(val_df['ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "val_no_of_ratings = torch.tensor(val_df['no_of_ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "val_actual_price = torch.tensor(val_df['actual_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "val_discount_price = torch.tensor(val_df['discount_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "val_labels = torch.tensor(val_df['int_rating'].values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine tensors into TensorDatasets\n",
    "# train_dataset = TensorDataset(train_product_ids, train_category_ids, train_subcategory_ids, train_ratings, train_no_of_ratings, train_actual_price, train_discount_price, train_labels)\n",
    "# val_dataset = TensorDataset(val_product_ids, val_category_ids, val_subcategory_ids, val_ratings, val_no_of_ratings, val_actual_price, val_discount_price, val_labels)\n",
    "\n",
    "# train_dataset = TensorDataset(train_category_ids, train_subcategory_ids, train_ratings, train_no_of_ratings, train_actual_price, train_discount_price, train_labels)\n",
    "# val_dataset = TensorDataset(val_category_ids, val_subcategory_ids, val_ratings, val_no_of_ratings, val_actual_price, val_discount_price, val_labels)\n",
    "\n",
    "train_dataset = TensorDataset(train_category_ids, train_no_of_ratings,  train_discount_price, train_labels)\n",
    "val_dataset = TensorDataset(val_category_ids, val_no_of_ratings, val_discount_price, val_labels)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Dataset class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RecommendationModel(nn.Module):\n",
    "    # def __init__(self, num_categories, num_subcategories, embedding_dim=10):\n",
    "    def __init__(self, num_categories, embedding_dim=10):\n",
    "        super(RecommendationModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for categorical features\n",
    "        self.category_embedding = nn.Embedding(num_categories, embedding_dim // 2)\n",
    "        # self.subcategory_embedding = nn.Embedding(num_subcategories, embedding_dim // 2)\n",
    "        \n",
    "        dropout_rate = 0.5\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear((embedding_dim // 2) + 2, 128)  # Increased capacity in the first layer\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.dropout3 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.dropout4 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        self.fc5 = nn.Linear(16, 3)    # Output layer with 3 units for 3 classes\n",
    "        \n",
    "        \n",
    "        \n",
    "    # def forward(self, category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price):\n",
    "    def forward(self, category_id, no_of_ratings,  discount_price):\n",
    "        # Pass inputs through embeddings\n",
    "        category_embedded = self.category_embedding(category_id)\n",
    "        # subcategory_embedded = self.subcategory_embedding(subcategory_id)\n",
    "        \n",
    "        # Flatten the embedding outputs\n",
    "        category_embedded = category_embedded.view(-1, self.category_embedding.embedding_dim)\n",
    "        # subcategory_embedded = subcategory_embedded.view(-1, self.subcategory_embedding.embedding_dim)\n",
    "        \n",
    "        # Concatenate all features (embeddings + numerical features)\n",
    "        # concatenated = torch.cat((category_embedded, subcategory_embedded, ratings, no_of_ratings, actual_price, discount_price), dim=1)\n",
    "        concatenated = torch.cat((category_embedded, no_of_ratings, discount_price), dim=1)\n",
    "        \n",
    "        # Pass through fully connected layers with ReLU activation\n",
    "        x = torch.relu(self.fc1(concatenated))\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        \n",
    "        output = self.fc5(x)  # Output layer\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize metrics trackers\n",
    "def compute_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    return accuracy_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "\n",
    "def compute_auc(predictions, labels, num_classes):\n",
    "    predictions_prob = F.softmax(predictions, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    if num_classes == 2:\n",
    "        return roc_auc_score(labels, predictions_prob[:, 1])  # For binary classification\n",
    "    else:\n",
    "        return roc_auc_score(labels, predictions_prob, multi_class='ovr')  # For multi-class classification\n",
    "    \n",
    "def logging(log_path, log_text):\n",
    "    with open(log_path, 'a') as file:\n",
    "        file.write(log_text + '\\n')\n",
    "        \n",
    "\n",
    "def calculate_average_auc(probs, labels, num_classes=3):\n",
    "    # Detach tensors and convert them to NumPy arrays\n",
    "    probs_np = probs.detach().numpy()\n",
    "    labels_np = labels.detach().numpy()\n",
    "    \n",
    "    aucs = []\n",
    "    labels_one_hot = F.one_hot(torch.tensor(labels_np), num_classes).numpy()  # Convert labels to one-hot encoding\n",
    "    for i in range(num_classes):\n",
    "        auc = roc_auc_score(labels_one_hot[:, i], probs_np[:, i])\n",
    "        aucs.append(auc)\n",
    "    return np.mean(aucs)  # Return the average AUC\n",
    "\n",
    "\n",
    "def calculate_precision_f1(probs, labels, num_classes=3):\n",
    "    # Detach tensors and convert them to NumPy arrays\n",
    "    probs_np = probs.detach().numpy()\n",
    "    labels_np = labels.detach().numpy()\n",
    "\n",
    "    # Convert probabilities to predicted class labels\n",
    "    preds = probs_np.argmax(axis=1)\n",
    "\n",
    "    # Calculate precision and F1 score for each class\n",
    "    precision = precision_score(labels_np, preds, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(labels_np, preds, average='weighted')\n",
    "    \n",
    "    return precision, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization and Training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "num_products = len(df['encoded_product'].unique())\n",
    "num_categories = len(df['encoded_main_category'].unique())\n",
    "# num_subcategories = len(df['encoded_sub_category'].unique())\n",
    "\n",
    "# model = RecommendationModel(num_products, num_categories, num_subcategories)\n",
    "# model = RecommendationModel(num_categories, num_subcategories, embedding_dim=10)\n",
    "model = RecommendationModel(num_categories, embedding_dim=10)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()  # Since it's a multi-class classification problem\n",
    "# criterion = nn.BCEWithLogitsLoss()  # Since it's a multi-class classification problem\n",
    "\n",
    "# Define Optimizer and Scheduler and Learning Rate\n",
    "# {'learning_rate': 0.00047307239371176485, 'weight_decay': 0.0002572176180532664, 'dropout_rate': 0.1475648189305909, 'embedding_dim': 10}\n",
    "\n",
    "num_epochs = 150\n",
    "initial_lr = 0.001\n",
    "exponent = 0.96\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr, weight_decay=1e-5)\n",
    "scheduler = ExponentialLR(optimizer, gamma=exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecommendationModel(\n",
      "  (category_embedding): Embedding(10, 5)\n",
      "  (fc1): Linear(in_features=7, out_features=128, bias=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (dropout3): Dropout(p=0.5, inplace=False)\n",
      "  (fc4): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (dropout4): Dropout(p=0.5, inplace=False)\n",
      "  (fc5): Linear(in_features=16, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch: 1/150\n",
      "Epoch [1/150] | Train Loss: 0.8819 | Val Loss: 0.8220 | Train Accuracy: 0.4940 | Val Accuracy: 0.5508 | Train Precision: 0.4868 | Val Precision: 0.5716 | train F1: 0.4898 | Val F1: 0.5346 | Epoch Time: 3.77s | Learning Rate: 0.001000\n",
      "\n",
      "Saved new best model with Val_Loss: 0.822\n",
      "\n",
      "Epoch: 2/150\n",
      "Epoch [2/150] | Train Loss: 0.8377 | Val Loss: 0.8125 | Train Accuracy: 0.5419 | Val Accuracy: 0.5550 | Train Precision: 0.5671 | Val Precision: 0.5838 | train F1: 0.5145 | Val F1: 0.5274 | Epoch Time: 3.59s | Learning Rate: 0.000960\n",
      "\n",
      "Saved new best model with Val_Loss: 0.812\n",
      "\n",
      "Epoch: 3/150\n",
      "Epoch [3/150] | Train Loss: 0.8268 | Val Loss: 0.8068 | Train Accuracy: 0.5468 | Val Accuracy: 0.5648 | Train Precision: 0.5759 | Val Precision: 0.5897 | train F1: 0.5147 | Val F1: 0.5437 | Epoch Time: 3.65s | Learning Rate: 0.000922\n",
      "\n",
      "Saved new best model with Val_Loss: 0.807\n",
      "\n",
      "Epoch: 4/150\n",
      "Epoch [4/150] | Train Loss: 0.8260 | Val Loss: 0.8089 | Train Accuracy: 0.5510 | Val Accuracy: 0.5611 | Train Precision: 0.5783 | Val Precision: 0.5871 | train F1: 0.5230 | Val F1: 0.5384 | Epoch Time: 3.54s | Learning Rate: 0.000885\n",
      "Epoch: 5/150\n",
      "Epoch [5/150] | Train Loss: 0.8263 | Val Loss: 0.8084 | Train Accuracy: 0.5514 | Val Accuracy: 0.5604 | Train Precision: 0.5801 | Val Precision: 0.5885 | train F1: 0.5216 | Val F1: 0.5349 | Epoch Time: 3.43s | Learning Rate: 0.000849\n",
      "Epoch: 6/150\n",
      "Epoch [6/150] | Train Loss: 0.8228 | Val Loss: 0.8072 | Train Accuracy: 0.5544 | Val Accuracy: 0.5602 | Train Precision: 0.5819 | Val Precision: 0.5882 | train F1: 0.5271 | Val F1: 0.5349 | Epoch Time: 3.47s | Learning Rate: 0.000815\n",
      "Epoch: 7/150\n",
      "Epoch [7/150] | Train Loss: 0.8222 | Val Loss: 0.8056 | Train Accuracy: 0.5546 | Val Accuracy: 0.5621 | Train Precision: 0.5823 | Val Precision: 0.5892 | train F1: 0.5269 | Val F1: 0.5379 | Epoch Time: 3.45s | Learning Rate: 0.000783\n",
      "\n",
      "Saved new best model with Val_Loss: 0.806\n",
      "\n",
      "Epoch: 8/150\n",
      "Epoch [8/150] | Train Loss: 0.8200 | Val Loss: 0.8051 | Train Accuracy: 0.5540 | Val Accuracy: 0.5653 | Train Precision: 0.5798 | Val Precision: 0.5899 | train F1: 0.5296 | Val F1: 0.5448 | Epoch Time: 3.49s | Learning Rate: 0.000751\n",
      "\n",
      "Saved new best model with Val_Loss: 0.805\n",
      "\n",
      "Epoch: 9/150\n",
      "Epoch [9/150] | Train Loss: 0.8185 | Val Loss: 0.8032 | Train Accuracy: 0.5584 | Val Accuracy: 0.5670 | Train Precision: 0.5831 | Val Precision: 0.5905 | train F1: 0.5361 | Val F1: 0.5479 | Epoch Time: 3.80s | Learning Rate: 0.000721\n",
      "\n",
      "Saved new best model with Val_Loss: 0.803\n",
      "\n",
      "Epoch: 10/150\n",
      "Epoch [10/150] | Train Loss: 0.8166 | Val Loss: 0.8035 | Train Accuracy: 0.5584 | Val Accuracy: 0.5724 | Train Precision: 0.5839 | Val Precision: 0.5938 | train F1: 0.5351 | Val F1: 0.5555 | Epoch Time: 3.52s | Learning Rate: 0.000693\n",
      "Epoch: 11/150\n",
      "Epoch [11/150] | Train Loss: 0.8157 | Val Loss: 0.8015 | Train Accuracy: 0.5608 | Val Accuracy: 0.5682 | Train Precision: 0.5843 | Val Precision: 0.5915 | train F1: 0.5407 | Val F1: 0.5494 | Epoch Time: 3.57s | Learning Rate: 0.000665\n",
      "\n",
      "Saved new best model with Val_Loss: 0.802\n",
      "\n",
      "Epoch: 12/150\n",
      "Epoch [12/150] | Train Loss: 0.8141 | Val Loss: 0.8030 | Train Accuracy: 0.5597 | Val Accuracy: 0.5693 | Train Precision: 0.5835 | Val Precision: 0.5939 | train F1: 0.5386 | Val F1: 0.5491 | Epoch Time: 3.49s | Learning Rate: 0.000638\n",
      "Epoch: 13/150\n",
      "Epoch [13/150] | Train Loss: 0.8144 | Val Loss: 0.8008 | Train Accuracy: 0.5617 | Val Accuracy: 0.5690 | Train Precision: 0.5840 | Val Precision: 0.5919 | train F1: 0.5430 | Val F1: 0.5507 | Epoch Time: 3.91s | Learning Rate: 0.000613\n",
      "\n",
      "Saved new best model with Val_Loss: 0.801\n",
      "\n",
      "Epoch: 14/150\n",
      "Epoch [14/150] | Train Loss: 0.8140 | Val Loss: 0.8003 | Train Accuracy: 0.5649 | Val Accuracy: 0.5676 | Train Precision: 0.5876 | Val Precision: 0.5904 | train F1: 0.5460 | Val F1: 0.5497 | Epoch Time: 3.59s | Learning Rate: 0.000588\n",
      "\n",
      "Saved new best model with Val_Loss: 0.800\n",
      "\n",
      "Epoch: 15/150\n",
      "Epoch [15/150] | Train Loss: 0.8142 | Val Loss: 0.8003 | Train Accuracy: 0.5652 | Val Accuracy: 0.5719 | Train Precision: 0.5873 | Val Precision: 0.5939 | train F1: 0.5471 | Val F1: 0.5548 | Epoch Time: 3.68s | Learning Rate: 0.000565\n",
      "\n",
      "Saved new best model with Val_Loss: 0.800\n",
      "\n",
      "Epoch: 16/150\n",
      "Epoch [16/150] | Train Loss: 0.8128 | Val Loss: 0.7979 | Train Accuracy: 0.5640 | Val Accuracy: 0.5771 | Train Precision: 0.5852 | Val Precision: 0.5975 | train F1: 0.5475 | Val F1: 0.5617 | Epoch Time: 3.62s | Learning Rate: 0.000542\n",
      "\n",
      "Saved new best model with Val_Loss: 0.798\n",
      "\n",
      "Epoch: 17/150\n",
      "Epoch [17/150] | Train Loss: 0.8116 | Val Loss: 0.7987 | Train Accuracy: 0.5653 | Val Accuracy: 0.5756 | Train Precision: 0.5861 | Val Precision: 0.5963 | train F1: 0.5494 | Val F1: 0.5598 | Epoch Time: 3.64s | Learning Rate: 0.000520\n",
      "Epoch: 18/150\n",
      "Epoch [18/150] | Train Loss: 0.8112 | Val Loss: 0.8001 | Train Accuracy: 0.5667 | Val Accuracy: 0.5751 | Train Precision: 0.5874 | Val Precision: 0.5967 | train F1: 0.5509 | Val F1: 0.5582 | Epoch Time: 3.88s | Learning Rate: 0.000500\n",
      "Epoch: 19/150\n",
      "Epoch [19/150] | Train Loss: 0.8110 | Val Loss: 0.7971 | Train Accuracy: 0.5686 | Val Accuracy: 0.5764 | Train Precision: 0.5894 | Val Precision: 0.5968 | train F1: 0.5525 | Val F1: 0.5609 | Epoch Time: 3.69s | Learning Rate: 0.000480\n",
      "\n",
      "Saved new best model with Val_Loss: 0.797\n",
      "\n",
      "Epoch: 20/150\n",
      "Epoch [20/150] | Train Loss: 0.8112 | Val Loss: 0.7981 | Train Accuracy: 0.5655 | Val Accuracy: 0.5744 | Train Precision: 0.5863 | Val Precision: 0.5966 | train F1: 0.5495 | Val F1: 0.5570 | Epoch Time: 3.63s | Learning Rate: 0.000460\n",
      "Epoch: 21/150\n",
      "Epoch [21/150] | Train Loss: 0.8112 | Val Loss: 0.7992 | Train Accuracy: 0.5648 | Val Accuracy: 0.5690 | Train Precision: 0.5860 | Val Precision: 0.5920 | train F1: 0.5482 | Val F1: 0.5507 | Epoch Time: 3.65s | Learning Rate: 0.000442\n",
      "Epoch: 22/150\n",
      "Epoch [22/150] | Train Loss: 0.8107 | Val Loss: 0.8011 | Train Accuracy: 0.5665 | Val Accuracy: 0.5692 | Train Precision: 0.5878 | Val Precision: 0.5920 | train F1: 0.5498 | Val F1: 0.5513 | Epoch Time: 3.71s | Learning Rate: 0.000424\n",
      "Epoch: 23/150\n",
      "Epoch [23/150] | Train Loss: 0.8091 | Val Loss: 0.7985 | Train Accuracy: 0.5647 | Val Accuracy: 0.5742 | Train Precision: 0.5864 | Val Precision: 0.5955 | train F1: 0.5477 | Val F1: 0.5580 | Epoch Time: 3.63s | Learning Rate: 0.000407\n",
      "Epoch: 24/150\n",
      "Epoch [24/150] | Train Loss: 0.8115 | Val Loss: 0.8003 | Train Accuracy: 0.5659 | Val Accuracy: 0.5720 | Train Precision: 0.5869 | Val Precision: 0.5943 | train F1: 0.5498 | Val F1: 0.5546 | Epoch Time: 3.61s | Learning Rate: 0.000391\n",
      "Epoch: 25/150\n",
      "Epoch [25/150] | Train Loss: 0.8102 | Val Loss: 0.7985 | Train Accuracy: 0.5674 | Val Accuracy: 0.5762 | Train Precision: 0.5882 | Val Precision: 0.5983 | train F1: 0.5514 | Val F1: 0.5591 | Epoch Time: 3.64s | Learning Rate: 0.000375\n",
      "Epoch: 26/150\n",
      "Epoch [26/150] | Train Loss: 0.8098 | Val Loss: 0.7984 | Train Accuracy: 0.5668 | Val Accuracy: 0.5742 | Train Precision: 0.5871 | Val Precision: 0.5952 | train F1: 0.5516 | Val F1: 0.5585 | Epoch Time: 3.79s | Learning Rate: 0.000360\n",
      "Epoch: 27/150\n",
      "Epoch [27/150] | Train Loss: 0.8094 | Val Loss: 0.7988 | Train Accuracy: 0.5676 | Val Accuracy: 0.5741 | Train Precision: 0.5880 | Val Precision: 0.5962 | train F1: 0.5522 | Val F1: 0.5569 | Epoch Time: 3.80s | Learning Rate: 0.000346\n",
      "Epoch: 28/150\n",
      "Epoch [28/150] | Train Loss: 0.8075 | Val Loss: 0.7987 | Train Accuracy: 0.5679 | Val Accuracy: 0.5732 | Train Precision: 0.5884 | Val Precision: 0.5958 | train F1: 0.5522 | Val F1: 0.5555 | Epoch Time: 3.63s | Learning Rate: 0.000332\n",
      "Epoch: 29/150\n",
      "Epoch [29/150] | Train Loss: 0.8096 | Val Loss: 0.7977 | Train Accuracy: 0.5664 | Val Accuracy: 0.5710 | Train Precision: 0.5879 | Val Precision: 0.5934 | train F1: 0.5492 | Val F1: 0.5534 | Epoch Time: 3.84s | Learning Rate: 0.000319\n",
      "Epoch: 30/150\n",
      "Epoch [30/150] | Train Loss: 0.8093 | Val Loss: 0.7983 | Train Accuracy: 0.5649 | Val Accuracy: 0.5722 | Train Precision: 0.5856 | Val Precision: 0.5938 | train F1: 0.5493 | Val F1: 0.5556 | Epoch Time: 3.59s | Learning Rate: 0.000306\n",
      "Epoch: 31/150\n",
      "Epoch [31/150] | Train Loss: 0.8097 | Val Loss: 0.7974 | Train Accuracy: 0.5684 | Val Accuracy: 0.5764 | Train Precision: 0.5897 | Val Precision: 0.5974 | train F1: 0.5517 | Val F1: 0.5606 | Epoch Time: 4.08s | Learning Rate: 0.000294\n",
      "Epoch: 32/150\n",
      "Epoch [32/150] | Train Loss: 0.8089 | Val Loss: 0.7982 | Train Accuracy: 0.5684 | Val Accuracy: 0.5695 | Train Precision: 0.5888 | Val Precision: 0.5925 | train F1: 0.5529 | Val F1: 0.5513 | Epoch Time: 3.86s | Learning Rate: 0.000282\n",
      "Epoch: 33/150\n",
      "Epoch [33/150] | Train Loss: 0.8064 | Val Loss: 0.7966 | Train Accuracy: 0.5687 | Val Accuracy: 0.5735 | Train Precision: 0.5900 | Val Precision: 0.5963 | train F1: 0.5520 | Val F1: 0.5555 | Epoch Time: 3.64s | Learning Rate: 0.000271\n",
      "\n",
      "Saved new best model with Val_Loss: 0.797\n",
      "\n",
      "Epoch: 34/150\n",
      "Epoch [34/150] | Train Loss: 0.8064 | Val Loss: 0.7967 | Train Accuracy: 0.5688 | Val Accuracy: 0.5737 | Train Precision: 0.5905 | Val Precision: 0.5963 | train F1: 0.5515 | Val F1: 0.5559 | Epoch Time: 3.64s | Learning Rate: 0.000260\n",
      "Epoch: 35/150\n",
      "Epoch [35/150] | Train Loss: 0.8076 | Val Loss: 0.7964 | Train Accuracy: 0.5680 | Val Accuracy: 0.5757 | Train Precision: 0.5893 | Val Precision: 0.5973 | train F1: 0.5516 | Val F1: 0.5591 | Epoch Time: 3.66s | Learning Rate: 0.000250\n",
      "\n",
      "Saved new best model with Val_Loss: 0.796\n",
      "\n",
      "Epoch: 36/150\n",
      "Epoch [36/150] | Train Loss: 0.8058 | Val Loss: 0.7963 | Train Accuracy: 0.5713 | Val Accuracy: 0.5742 | Train Precision: 0.5920 | Val Precision: 0.5962 | train F1: 0.5553 | Val F1: 0.5572 | Epoch Time: 3.62s | Learning Rate: 0.000240\n",
      "\n",
      "Saved new best model with Val_Loss: 0.796\n",
      "\n",
      "Epoch: 37/150\n",
      "Epoch [37/150] | Train Loss: 0.8072 | Val Loss: 0.7963 | Train Accuracy: 0.5696 | Val Accuracy: 0.5781 | Train Precision: 0.5904 | Val Precision: 0.5986 | train F1: 0.5536 | Val F1: 0.5626 | Epoch Time: 3.62s | Learning Rate: 0.000230\n",
      "\n",
      "Saved new best model with Val_Loss: 0.796\n",
      "\n",
      "Epoch: 38/150\n",
      "Epoch [38/150] | Train Loss: 0.8069 | Val Loss: 0.7963 | Train Accuracy: 0.5717 | Val Accuracy: 0.5783 | Train Precision: 0.5922 | Val Precision: 0.5989 | train F1: 0.5561 | Val F1: 0.5624 | Epoch Time: 3.62s | Learning Rate: 0.000221\n",
      "Epoch: 39/150\n",
      "Epoch [39/150] | Train Loss: 0.8074 | Val Loss: 0.7969 | Train Accuracy: 0.5689 | Val Accuracy: 0.5768 | Train Precision: 0.5893 | Val Precision: 0.5982 | train F1: 0.5535 | Val F1: 0.5601 | Epoch Time: 3.61s | Learning Rate: 0.000212\n",
      "Epoch: 40/150\n",
      "Epoch [40/150] | Train Loss: 0.8075 | Val Loss: 0.7967 | Train Accuracy: 0.5688 | Val Accuracy: 0.5756 | Train Precision: 0.5890 | Val Precision: 0.5969 | train F1: 0.5536 | Val F1: 0.5592 | Epoch Time: 3.99s | Learning Rate: 0.000204\n",
      "Epoch: 41/150\n",
      "Epoch [41/150] | Train Loss: 0.8073 | Val Loss: 0.7963 | Train Accuracy: 0.5746 | Val Accuracy: 0.5776 | Train Precision: 0.5951 | Val Precision: 0.5992 | train F1: 0.5590 | Val F1: 0.5608 | Epoch Time: 4.03s | Learning Rate: 0.000195\n",
      "Epoch: 42/150\n",
      "Epoch [42/150] | Train Loss: 0.8063 | Val Loss: 0.7970 | Train Accuracy: 0.5686 | Val Accuracy: 0.5735 | Train Precision: 0.5891 | Val Precision: 0.5955 | train F1: 0.5530 | Val F1: 0.5566 | Epoch Time: 4.10s | Learning Rate: 0.000188\n",
      "Epoch: 43/150\n",
      "Epoch [43/150] | Train Loss: 0.8081 | Val Loss: 0.7962 | Train Accuracy: 0.5707 | Val Accuracy: 0.5771 | Train Precision: 0.5911 | Val Precision: 0.5983 | train F1: 0.5553 | Val F1: 0.5606 | Epoch Time: 3.88s | Learning Rate: 0.000180\n",
      "\n",
      "Saved new best model with Val_Loss: 0.796\n",
      "\n",
      "Epoch: 44/150\n",
      "Epoch [44/150] | Train Loss: 0.8057 | Val Loss: 0.7970 | Train Accuracy: 0.5750 | Val Accuracy: 0.5744 | Train Precision: 0.5950 | Val Precision: 0.5966 | train F1: 0.5599 | Val F1: 0.5570 | Epoch Time: 4.32s | Learning Rate: 0.000173\n",
      "Epoch: 45/150\n",
      "Epoch [45/150] | Train Loss: 0.8049 | Val Loss: 0.7962 | Train Accuracy: 0.5736 | Val Accuracy: 0.5769 | Train Precision: 0.5936 | Val Precision: 0.5988 | train F1: 0.5584 | Val F1: 0.5597 | Epoch Time: 4.14s | Learning Rate: 0.000166\n",
      "\n",
      "Saved new best model with Val_Loss: 0.796\n",
      "\n",
      "Epoch: 46/150\n",
      "Epoch [46/150] | Train Loss: 0.8049 | Val Loss: 0.7951 | Train Accuracy: 0.5746 | Val Accuracy: 0.5771 | Train Precision: 0.5948 | Val Precision: 0.5969 | train F1: 0.5592 | Val F1: 0.5622 | Epoch Time: 4.09s | Learning Rate: 0.000159\n",
      "\n",
      "Saved new best model with Val_Loss: 0.795\n",
      "\n",
      "Epoch: 47/150\n",
      "Epoch [47/150] | Train Loss: 0.8077 | Val Loss: 0.7961 | Train Accuracy: 0.5684 | Val Accuracy: 0.5746 | Train Precision: 0.5884 | Val Precision: 0.5953 | train F1: 0.5536 | Val F1: 0.5590 | Epoch Time: 3.98s | Learning Rate: 0.000153\n",
      "Epoch: 48/150\n",
      "Epoch [48/150] | Train Loss: 0.8055 | Val Loss: 0.7950 | Train Accuracy: 0.5709 | Val Accuracy: 0.5764 | Train Precision: 0.5909 | Val Precision: 0.5968 | train F1: 0.5560 | Val F1: 0.5612 | Epoch Time: 3.98s | Learning Rate: 0.000147\n",
      "\n",
      "Saved new best model with Val_Loss: 0.795\n",
      "\n",
      "Epoch: 49/150\n",
      "Epoch [49/150] | Train Loss: 0.8055 | Val Loss: 0.7958 | Train Accuracy: 0.5714 | Val Accuracy: 0.5741 | Train Precision: 0.5914 | Val Precision: 0.5949 | train F1: 0.5565 | Val F1: 0.5584 | Epoch Time: 4.03s | Learning Rate: 0.000141\n",
      "Epoch: 50/150\n",
      "Epoch [50/150] | Train Loss: 0.8065 | Val Loss: 0.7953 | Train Accuracy: 0.5705 | Val Accuracy: 0.5734 | Train Precision: 0.5904 | Val Precision: 0.5941 | train F1: 0.5557 | Val F1: 0.5578 | Epoch Time: 3.98s | Learning Rate: 0.000135\n",
      "Epoch: 51/150\n",
      "Epoch [51/150] | Train Loss: 0.8066 | Val Loss: 0.7957 | Train Accuracy: 0.5719 | Val Accuracy: 0.5762 | Train Precision: 0.5922 | Val Precision: 0.5966 | train F1: 0.5566 | Val F1: 0.5609 | Epoch Time: 4.12s | Learning Rate: 0.000130\n",
      "Epoch: 52/150\n",
      "Epoch [52/150] | Train Loss: 0.8055 | Val Loss: 0.7956 | Train Accuracy: 0.5729 | Val Accuracy: 0.5749 | Train Precision: 0.5926 | Val Precision: 0.5955 | train F1: 0.5581 | Val F1: 0.5594 | Epoch Time: 4.00s | Learning Rate: 0.000125\n",
      "Epoch: 53/150\n",
      "Epoch [53/150] | Train Loss: 0.8062 | Val Loss: 0.7954 | Train Accuracy: 0.5718 | Val Accuracy: 0.5768 | Train Precision: 0.5917 | Val Precision: 0.5972 | train F1: 0.5568 | Val F1: 0.5612 | Epoch Time: 3.98s | Learning Rate: 0.000120\n",
      "Epoch: 54/150\n",
      "Epoch [54/150] | Train Loss: 0.8057 | Val Loss: 0.7967 | Train Accuracy: 0.5716 | Val Accuracy: 0.5752 | Train Precision: 0.5915 | Val Precision: 0.5965 | train F1: 0.5567 | Val F1: 0.5588 | Epoch Time: 3.90s | Learning Rate: 0.000115\n",
      "Epoch: 55/150\n",
      "Epoch [55/150] | Train Loss: 0.8052 | Val Loss: 0.7962 | Train Accuracy: 0.5701 | Val Accuracy: 0.5766 | Train Precision: 0.5902 | Val Precision: 0.5973 | train F1: 0.5551 | Val F1: 0.5609 | Epoch Time: 3.90s | Learning Rate: 0.000110\n",
      "Epoch: 56/150\n",
      "Epoch [56/150] | Train Loss: 0.8046 | Val Loss: 0.7960 | Train Accuracy: 0.5738 | Val Accuracy: 0.5771 | Train Precision: 0.5937 | Val Precision: 0.5981 | train F1: 0.5590 | Val F1: 0.5611 | Epoch Time: 3.89s | Learning Rate: 0.000106\n",
      "Epoch: 57/150\n",
      "Epoch [57/150] | Train Loss: 0.8046 | Val Loss: 0.7961 | Train Accuracy: 0.5715 | Val Accuracy: 0.5754 | Train Precision: 0.5912 | Val Precision: 0.5966 | train F1: 0.5568 | Val F1: 0.5591 | Epoch Time: 4.15s | Learning Rate: 0.000102\n",
      "Epoch: 58/150\n",
      "Epoch [58/150] | Train Loss: 0.8054 | Val Loss: 0.7963 | Train Accuracy: 0.5722 | Val Accuracy: 0.5759 | Train Precision: 0.5921 | Val Precision: 0.5970 | train F1: 0.5574 | Val F1: 0.5597 | Epoch Time: 3.90s | Learning Rate: 0.000098\n",
      "Epoch: 59/150\n",
      "Epoch [59/150] | Train Loss: 0.8032 | Val Loss: 0.7948 | Train Accuracy: 0.5693 | Val Accuracy: 0.5800 | Train Precision: 0.5891 | Val Precision: 0.5996 | train F1: 0.5548 | Val F1: 0.5651 | Epoch Time: 3.88s | Learning Rate: 0.000094\n",
      "\n",
      "Saved new best model with Val_Loss: 0.795\n",
      "\n",
      "Epoch: 60/150\n",
      "Epoch [60/150] | Train Loss: 0.8054 | Val Loss: 0.7952 | Train Accuracy: 0.5717 | Val Accuracy: 0.5784 | Train Precision: 0.5913 | Val Precision: 0.5991 | train F1: 0.5573 | Val F1: 0.5626 | Epoch Time: 4.08s | Learning Rate: 0.000090\n",
      "Epoch: 61/150\n",
      "Epoch [61/150] | Train Loss: 0.8053 | Val Loss: 0.7953 | Train Accuracy: 0.5705 | Val Accuracy: 0.5778 | Train Precision: 0.5903 | Val Precision: 0.5986 | train F1: 0.5560 | Val F1: 0.5617 | Epoch Time: 4.04s | Learning Rate: 0.000086\n",
      "Epoch: 62/150\n",
      "Epoch [62/150] | Train Loss: 0.8044 | Val Loss: 0.7960 | Train Accuracy: 0.5717 | Val Accuracy: 0.5759 | Train Precision: 0.5916 | Val Precision: 0.5973 | train F1: 0.5570 | Val F1: 0.5594 | Epoch Time: 3.93s | Learning Rate: 0.000083\n",
      "Epoch: 63/150\n",
      "Epoch [63/150] | Train Loss: 0.8054 | Val Loss: 0.7951 | Train Accuracy: 0.5710 | Val Accuracy: 0.5783 | Train Precision: 0.5912 | Val Precision: 0.5988 | train F1: 0.5558 | Val F1: 0.5625 | Epoch Time: 3.92s | Learning Rate: 0.000080\n",
      "Epoch: 64/150\n",
      "Epoch [64/150] | Train Loss: 0.8053 | Val Loss: 0.7954 | Train Accuracy: 0.5715 | Val Accuracy: 0.5768 | Train Precision: 0.5914 | Val Precision: 0.5982 | train F1: 0.5566 | Val F1: 0.5602 | Epoch Time: 3.89s | Learning Rate: 0.000076\n",
      "Epoch: 65/150\n",
      "Epoch [65/150] | Train Loss: 0.8055 | Val Loss: 0.7959 | Train Accuracy: 0.5722 | Val Accuracy: 0.5764 | Train Precision: 0.5925 | Val Precision: 0.5980 | train F1: 0.5568 | Val F1: 0.5596 | Epoch Time: 4.26s | Learning Rate: 0.000073\n",
      "Epoch: 66/150\n",
      "Epoch [66/150] | Train Loss: 0.8042 | Val Loss: 0.7951 | Train Accuracy: 0.5732 | Val Accuracy: 0.5783 | Train Precision: 0.5933 | Val Precision: 0.5991 | train F1: 0.5578 | Val F1: 0.5622 | Epoch Time: 4.35s | Learning Rate: 0.000070\n",
      "Epoch: 67/150\n",
      "Epoch [67/150] | Train Loss: 0.8055 | Val Loss: 0.7957 | Train Accuracy: 0.5709 | Val Accuracy: 0.5759 | Train Precision: 0.5910 | Val Precision: 0.5974 | train F1: 0.5556 | Val F1: 0.5593 | Epoch Time: 4.16s | Learning Rate: 0.000068\n",
      "Epoch: 68/150\n",
      "Epoch [68/150] | Train Loss: 0.8053 | Val Loss: 0.7953 | Train Accuracy: 0.5725 | Val Accuracy: 0.5773 | Train Precision: 0.5927 | Val Precision: 0.5982 | train F1: 0.5570 | Val F1: 0.5610 | Epoch Time: 3.92s | Learning Rate: 0.000065\n",
      "Epoch: 69/150\n",
      "Epoch [69/150] | Train Loss: 0.8054 | Val Loss: 0.7950 | Train Accuracy: 0.5716 | Val Accuracy: 0.5779 | Train Precision: 0.5917 | Val Precision: 0.5986 | train F1: 0.5564 | Val F1: 0.5621 | Epoch Time: 4.79s | Learning Rate: 0.000062\n",
      "Epoch: 70/150\n",
      "Epoch [70/150] | Train Loss: 0.8042 | Val Loss: 0.7947 | Train Accuracy: 0.5706 | Val Accuracy: 0.5774 | Train Precision: 0.5903 | Val Precision: 0.5984 | train F1: 0.5560 | Val F1: 0.5613 | Epoch Time: 4.74s | Learning Rate: 0.000060\n",
      "\n",
      "Saved new best model with Val_Loss: 0.795\n",
      "\n",
      "Epoch: 71/150\n",
      "Epoch [71/150] | Train Loss: 0.8034 | Val Loss: 0.7947 | Train Accuracy: 0.5723 | Val Accuracy: 0.5771 | Train Precision: 0.5924 | Val Precision: 0.5981 | train F1: 0.5569 | Val F1: 0.5608 | Epoch Time: 4.30s | Learning Rate: 0.000057\n",
      "Epoch: 72/150\n",
      "Epoch [72/150] | Train Loss: 0.8049 | Val Loss: 0.7945 | Train Accuracy: 0.5722 | Val Accuracy: 0.5781 | Train Precision: 0.5922 | Val Precision: 0.5987 | train F1: 0.5571 | Val F1: 0.5622 | Epoch Time: 4.12s | Learning Rate: 0.000055\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 73/150\n",
      "Epoch [73/150] | Train Loss: 0.8046 | Val Loss: 0.7949 | Train Accuracy: 0.5734 | Val Accuracy: 0.5781 | Train Precision: 0.5931 | Val Precision: 0.5990 | train F1: 0.5588 | Val F1: 0.5619 | Epoch Time: 4.82s | Learning Rate: 0.000053\n",
      "Epoch: 74/150\n",
      "Epoch [74/150] | Train Loss: 0.8055 | Val Loss: 0.7952 | Train Accuracy: 0.5729 | Val Accuracy: 0.5781 | Train Precision: 0.5929 | Val Precision: 0.5990 | train F1: 0.5578 | Val F1: 0.5619 | Epoch Time: 4.21s | Learning Rate: 0.000051\n",
      "Epoch: 75/150\n",
      "Epoch [75/150] | Train Loss: 0.8058 | Val Loss: 0.7953 | Train Accuracy: 0.5688 | Val Accuracy: 0.5773 | Train Precision: 0.5887 | Val Precision: 0.5983 | train F1: 0.5541 | Val F1: 0.5610 | Epoch Time: 4.20s | Learning Rate: 0.000049\n",
      "Epoch: 76/150\n",
      "Epoch [76/150] | Train Loss: 0.8054 | Val Loss: 0.7945 | Train Accuracy: 0.5737 | Val Accuracy: 0.5784 | Train Precision: 0.5937 | Val Precision: 0.5990 | train F1: 0.5584 | Val F1: 0.5626 | Epoch Time: 4.47s | Learning Rate: 0.000047\n",
      "Epoch: 77/150\n",
      "Epoch [77/150] | Train Loss: 0.8036 | Val Loss: 0.7951 | Train Accuracy: 0.5722 | Val Accuracy: 0.5769 | Train Precision: 0.5921 | Val Precision: 0.5981 | train F1: 0.5574 | Val F1: 0.5606 | Epoch Time: 5.61s | Learning Rate: 0.000045\n",
      "Epoch: 78/150\n",
      "Epoch [78/150] | Train Loss: 0.8037 | Val Loss: 0.7944 | Train Accuracy: 0.5703 | Val Accuracy: 0.5784 | Train Precision: 0.5906 | Val Precision: 0.5990 | train F1: 0.5549 | Val F1: 0.5627 | Epoch Time: 4.00s | Learning Rate: 0.000043\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 79/150\n",
      "Epoch [79/150] | Train Loss: 0.8048 | Val Loss: 0.7946 | Train Accuracy: 0.5718 | Val Accuracy: 0.5784 | Train Precision: 0.5916 | Val Precision: 0.5989 | train F1: 0.5571 | Val F1: 0.5627 | Epoch Time: 4.05s | Learning Rate: 0.000041\n",
      "Epoch: 80/150\n",
      "Epoch [80/150] | Train Loss: 0.8043 | Val Loss: 0.7953 | Train Accuracy: 0.5748 | Val Accuracy: 0.5773 | Train Precision: 0.5944 | Val Precision: 0.5984 | train F1: 0.5600 | Val F1: 0.5610 | Epoch Time: 4.35s | Learning Rate: 0.000040\n",
      "Epoch: 81/150\n",
      "Epoch [81/150] | Train Loss: 0.8034 | Val Loss: 0.7947 | Train Accuracy: 0.5727 | Val Accuracy: 0.5784 | Train Precision: 0.5928 | Val Precision: 0.5990 | train F1: 0.5576 | Val F1: 0.5626 | Epoch Time: 4.31s | Learning Rate: 0.000038\n",
      "Epoch: 82/150\n",
      "Epoch [82/150] | Train Loss: 0.8044 | Val Loss: 0.7947 | Train Accuracy: 0.5731 | Val Accuracy: 0.5784 | Train Precision: 0.5930 | Val Precision: 0.5989 | train F1: 0.5582 | Val F1: 0.5627 | Epoch Time: 3.92s | Learning Rate: 0.000037\n",
      "Epoch: 83/150\n",
      "Epoch [83/150] | Train Loss: 0.8048 | Val Loss: 0.7946 | Train Accuracy: 0.5723 | Val Accuracy: 0.5786 | Train Precision: 0.5920 | Val Precision: 0.5992 | train F1: 0.5575 | Val F1: 0.5628 | Epoch Time: 3.98s | Learning Rate: 0.000035\n",
      "Epoch: 84/150\n",
      "Epoch [84/150] | Train Loss: 0.8016 | Val Loss: 0.7944 | Train Accuracy: 0.5744 | Val Accuracy: 0.5781 | Train Precision: 0.5939 | Val Precision: 0.5987 | train F1: 0.5600 | Val F1: 0.5622 | Epoch Time: 3.95s | Learning Rate: 0.000034\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 85/150\n",
      "Epoch [85/150] | Train Loss: 0.8051 | Val Loss: 0.7946 | Train Accuracy: 0.5729 | Val Accuracy: 0.5781 | Train Precision: 0.5928 | Val Precision: 0.5988 | train F1: 0.5579 | Val F1: 0.5622 | Epoch Time: 4.07s | Learning Rate: 0.000032\n",
      "Epoch: 86/150\n",
      "Epoch [86/150] | Train Loss: 0.8054 | Val Loss: 0.7945 | Train Accuracy: 0.5731 | Val Accuracy: 0.5791 | Train Precision: 0.5930 | Val Precision: 0.5996 | train F1: 0.5582 | Val F1: 0.5634 | Epoch Time: 4.78s | Learning Rate: 0.000031\n",
      "Epoch: 87/150\n",
      "Epoch [87/150] | Train Loss: 0.8044 | Val Loss: 0.7950 | Train Accuracy: 0.5721 | Val Accuracy: 0.5779 | Train Precision: 0.5920 | Val Precision: 0.5988 | train F1: 0.5572 | Val F1: 0.5618 | Epoch Time: 4.59s | Learning Rate: 0.000030\n",
      "Epoch: 88/150\n",
      "Epoch [88/150] | Train Loss: 0.8040 | Val Loss: 0.7947 | Train Accuracy: 0.5750 | Val Accuracy: 0.5784 | Train Precision: 0.5950 | Val Precision: 0.5990 | train F1: 0.5599 | Val F1: 0.5626 | Epoch Time: 4.49s | Learning Rate: 0.000029\n",
      "Epoch: 89/150\n",
      "Epoch [89/150] | Train Loss: 0.8024 | Val Loss: 0.7948 | Train Accuracy: 0.5743 | Val Accuracy: 0.5771 | Train Precision: 0.5942 | Val Precision: 0.5979 | train F1: 0.5595 | Val F1: 0.5611 | Epoch Time: 4.11s | Learning Rate: 0.000028\n",
      "Epoch: 90/150\n",
      "Epoch [90/150] | Train Loss: 0.8045 | Val Loss: 0.7945 | Train Accuracy: 0.5726 | Val Accuracy: 0.5788 | Train Precision: 0.5925 | Val Precision: 0.5993 | train F1: 0.5576 | Val F1: 0.5630 | Epoch Time: 3.95s | Learning Rate: 0.000026\n",
      "Epoch: 91/150\n",
      "Epoch [91/150] | Train Loss: 0.8039 | Val Loss: 0.7944 | Train Accuracy: 0.5731 | Val Accuracy: 0.5788 | Train Precision: 0.5928 | Val Precision: 0.5988 | train F1: 0.5584 | Val F1: 0.5633 | Epoch Time: 3.91s | Learning Rate: 0.000025\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 92/150\n",
      "Epoch [92/150] | Train Loss: 0.8035 | Val Loss: 0.7942 | Train Accuracy: 0.5701 | Val Accuracy: 0.5796 | Train Precision: 0.5900 | Val Precision: 0.5996 | train F1: 0.5551 | Val F1: 0.5642 | Epoch Time: 3.94s | Learning Rate: 0.000024\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 93/150\n",
      "Epoch [93/150] | Train Loss: 0.8047 | Val Loss: 0.7944 | Train Accuracy: 0.5761 | Val Accuracy: 0.5783 | Train Precision: 0.5958 | Val Precision: 0.5987 | train F1: 0.5612 | Val F1: 0.5625 | Epoch Time: 3.93s | Learning Rate: 0.000023\n",
      "Epoch: 94/150\n",
      "Epoch [94/150] | Train Loss: 0.8041 | Val Loss: 0.7944 | Train Accuracy: 0.5739 | Val Accuracy: 0.5788 | Train Precision: 0.5938 | Val Precision: 0.5992 | train F1: 0.5587 | Val F1: 0.5630 | Epoch Time: 4.00s | Learning Rate: 0.000022\n",
      "Epoch: 95/150\n",
      "Epoch [95/150] | Train Loss: 0.8044 | Val Loss: 0.7942 | Train Accuracy: 0.5704 | Val Accuracy: 0.5795 | Train Precision: 0.5904 | Val Precision: 0.5995 | train F1: 0.5554 | Val F1: 0.5640 | Epoch Time: 4.14s | Learning Rate: 0.000022\n",
      "\n",
      "Saved new best model with Val_Loss: 0.794\n",
      "\n",
      "Epoch: 96/150\n",
      "Epoch [96/150] | Train Loss: 0.8044 | Val Loss: 0.7942 | Train Accuracy: 0.5712 | Val Accuracy: 0.5786 | Train Precision: 0.5910 | Val Precision: 0.5988 | train F1: 0.5565 | Val F1: 0.5630 | Epoch Time: 3.95s | Learning Rate: 0.000021\n",
      "Epoch: 97/150\n",
      "Epoch [97/150] | Train Loss: 0.8034 | Val Loss: 0.7942 | Train Accuracy: 0.5732 | Val Accuracy: 0.5798 | Train Precision: 0.5930 | Val Precision: 0.5995 | train F1: 0.5584 | Val F1: 0.5646 | Epoch Time: 4.02s | Learning Rate: 0.000020\n",
      "Epoch: 98/150\n",
      "Epoch [98/150] | Train Loss: 0.8050 | Val Loss: 0.7944 | Train Accuracy: 0.5715 | Val Accuracy: 0.5789 | Train Precision: 0.5912 | Val Precision: 0.5992 | train F1: 0.5568 | Val F1: 0.5632 | Epoch Time: 3.90s | Learning Rate: 0.000019\n",
      "Epoch: 99/150\n",
      "Epoch [99/150] | Train Loss: 0.8059 | Val Loss: 0.7944 | Train Accuracy: 0.5734 | Val Accuracy: 0.5788 | Train Precision: 0.5932 | Val Precision: 0.5991 | train F1: 0.5585 | Val F1: 0.5630 | Epoch Time: 4.12s | Learning Rate: 0.000018\n",
      "Epoch: 100/150\n",
      "Epoch [100/150] | Train Loss: 0.8037 | Val Loss: 0.7943 | Train Accuracy: 0.5706 | Val Accuracy: 0.5788 | Train Precision: 0.5903 | Val Precision: 0.5989 | train F1: 0.5558 | Val F1: 0.5632 | Epoch Time: 4.00s | Learning Rate: 0.000018\n",
      "Epoch: 101/150\n",
      "Epoch [101/150] | Train Loss: 0.8047 | Val Loss: 0.7944 | Train Accuracy: 0.5740 | Val Accuracy: 0.5800 | Train Precision: 0.5937 | Val Precision: 0.6001 | train F1: 0.5591 | Val F1: 0.5644 | Epoch Time: 3.96s | Learning Rate: 0.000017\n",
      "Epoch: 102/150\n",
      "Epoch [102/150] | Train Loss: 0.8035 | Val Loss: 0.7943 | Train Accuracy: 0.5715 | Val Accuracy: 0.5805 | Train Precision: 0.5914 | Val Precision: 0.6003 | train F1: 0.5565 | Val F1: 0.5651 | Epoch Time: 4.09s | Learning Rate: 0.000016\n",
      "Epoch: 103/150\n",
      "Epoch [103/150] | Train Loss: 0.8036 | Val Loss: 0.7942 | Train Accuracy: 0.5713 | Val Accuracy: 0.5795 | Train Precision: 0.5911 | Val Precision: 0.5994 | train F1: 0.5565 | Val F1: 0.5640 | Epoch Time: 4.27s | Learning Rate: 0.000016\n",
      "Epoch: 104/150\n",
      "Epoch [104/150] | Train Loss: 0.8021 | Val Loss: 0.7944 | Train Accuracy: 0.5743 | Val Accuracy: 0.5791 | Train Precision: 0.5940 | Val Precision: 0.5993 | train F1: 0.5597 | Val F1: 0.5635 | Epoch Time: 4.01s | Learning Rate: 0.000015\n",
      "Epoch: 105/150\n",
      "Epoch [105/150] | Train Loss: 0.8038 | Val Loss: 0.7943 | Train Accuracy: 0.5755 | Val Accuracy: 0.5791 | Train Precision: 0.5951 | Val Precision: 0.5992 | train F1: 0.5608 | Val F1: 0.5635 | Epoch Time: 4.43s | Learning Rate: 0.000014\n",
      "Epoch: 106/150\n",
      "Epoch [106/150] | Train Loss: 0.8020 | Val Loss: 0.7942 | Train Accuracy: 0.5736 | Val Accuracy: 0.5805 | Train Precision: 0.5933 | Val Precision: 0.6003 | train F1: 0.5588 | Val F1: 0.5652 | Epoch Time: 4.38s | Learning Rate: 0.000014\n",
      "Epoch: 107/150\n",
      "Epoch [107/150] | Train Loss: 0.8045 | Val Loss: 0.7945 | Train Accuracy: 0.5731 | Val Accuracy: 0.5793 | Train Precision: 0.5927 | Val Precision: 0.5996 | train F1: 0.5584 | Val F1: 0.5635 | Epoch Time: 4.02s | Learning Rate: 0.000013\n",
      "Epoch: 108/150\n",
      "Epoch [108/150] | Train Loss: 0.8044 | Val Loss: 0.7944 | Train Accuracy: 0.5739 | Val Accuracy: 0.5795 | Train Precision: 0.5939 | Val Precision: 0.5997 | train F1: 0.5588 | Val F1: 0.5637 | Epoch Time: 4.10s | Learning Rate: 0.000013\n",
      "Epoch: 109/150\n",
      "Epoch [109/150] | Train Loss: 0.8039 | Val Loss: 0.7944 | Train Accuracy: 0.5731 | Val Accuracy: 0.5789 | Train Precision: 0.5929 | Val Precision: 0.5994 | train F1: 0.5582 | Val F1: 0.5631 | Epoch Time: 3.91s | Learning Rate: 0.000012\n",
      "Epoch: 110/150\n",
      "Epoch [110/150] | Train Loss: 0.8049 | Val Loss: 0.7944 | Train Accuracy: 0.5736 | Val Accuracy: 0.5791 | Train Precision: 0.5935 | Val Precision: 0.5993 | train F1: 0.5587 | Val F1: 0.5635 | Epoch Time: 3.96s | Learning Rate: 0.000012\n",
      "Validation loss has not improved for 15 epochs. Training Finished !!!\n",
      "Training Complete !!!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model = model.to(device)\n",
    "\n",
    "# Initialize best validation loss\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Variable to store probabilities when the best model is saved\n",
    "best_epoch_train_probs = None\n",
    "best_epoch_train_labels = None\n",
    "best_epoch_val_probs = None\n",
    "best_epoch_val_labels = None\n",
    "\n",
    "epoch_count = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "    start_time = time.time()  # Start epoch timer\n",
    "    \n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    train_probs = []\n",
    "    train_labels = []\n",
    "    \n",
    "    # Training loop\n",
    "    for batch in train_loader:\n",
    "        # category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "        category_id, no_of_ratings,  discount_price, labels = batch\n",
    "        \n",
    "        # Move data to the appropriate device\n",
    "        # category_id, subcategory_id = category_id.to(device), subcategory_id.to(device)\n",
    "        # ratings, no_of_ratings = ratings.to(device), no_of_ratings.to(device)\n",
    "        category_id = category_id.to(device)\n",
    "        no_of_ratings = no_of_ratings.to(device)\n",
    "        discount_price = discount_price.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(category_id, no_of_ratings, discount_price)\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        \n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        train_probs.append(probs.cpu())\n",
    "        train_labels.append(labels.cpu())\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_probs = torch.cat(train_probs)\n",
    "    train_labels = torch.cat(train_labels)\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = (train_probs.argmax(dim=1) == train_labels).float().mean().item()\n",
    "    # train_auc = calculate_average_auc(train_probs, train_labels)  # Calculate average AUC for training\n",
    "    train_precision, train_f1 = calculate_precision_f1(train_probs, train_labels)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_probs = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in val_loader:\n",
    "            # category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "            category_id, no_of_ratings, discount_price, labels = batch\n",
    "            \n",
    "            # Move data to the appropriate device\n",
    "            # category_id, subcategory_id = category_id.to(device), subcategory_id.to(device)\n",
    "            # ratings, no_of_ratings = ratings.to(device), no_of_ratings.to(device)\n",
    "            category_id = category_id.to(device)\n",
    "            no_of_ratings = no_of_ratings.to(device)\n",
    "            discount_price = discount_price.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # outputs = model(category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price)\n",
    "            outputs = model(category_id, no_of_ratings, discount_price)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Apply softmax to get probabilities\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            val_probs.append(probs.cpu())\n",
    "            val_labels.append(labels.cpu())\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_probs = torch.cat(val_probs)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = (val_probs.argmax(dim=1) == val_labels).float().mean().item()\n",
    "    # val_auc = calculate_average_auc(val_probs, val_labels)  # Calculate average AUC for validation\n",
    "    val_precision, val_f1 = calculate_precision_f1(val_probs, val_labels)\n",
    "\n",
    "    \n",
    "    # Calculate epoch time\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    # Learning rate\n",
    "    lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Print metrics including AUC\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}] | '\n",
    "          f'Train Loss: {train_loss:.4f} | '\n",
    "          f'Val Loss: {val_loss:.4f} | '\n",
    "          f'Train Accuracy: {train_accuracy:.4f} | '\n",
    "          f'Val Accuracy: {val_accuracy:.4f} | '\n",
    "          f'Train Precision: {train_precision:.4f} | '\n",
    "          f'Val Precision: {val_precision:.4f} | '\n",
    "          f'train F1: {train_f1:.4f} | '\n",
    "          f'Val F1: {val_f1:.4f} | '\n",
    "          f'Epoch Time: {epoch_time:.2f}s | '\n",
    "          f'Learning Rate: {lr:.6f}')\n",
    "    \n",
    "    # Learning rate scheduler step\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save the best model based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), os.path.join(weights_dir,'best_model.pth'))\n",
    "        print(f'\\nSaved new best model with Val_Loss: {val_loss:.3f}\\n')\n",
    "        epoch_count = 0\n",
    "        \n",
    "        # Store the probabilities of the best epoch\n",
    "        best_epoch_train_probs = train_probs.detach().numpy()\n",
    "        best_epoch_train_labels = train_labels.detach().numpy()\n",
    "        best_epoch_val_probs = val_probs.detach().numpy()\n",
    "        best_epoch_val_labels = val_labels.detach().numpy()\n",
    "        \n",
    "    if epoch_count == 15:\n",
    "        print(f'Validation loss has not improved for {epoch_count} epochs. Training Finished !!!')\n",
    "        break\n",
    "    epoch_count += 1\n",
    "\n",
    "# After training, save the probabilities of the best epoch\n",
    "if best_epoch_train_probs is not None:\n",
    "    train_prob_df = pd.DataFrame(best_epoch_train_probs, columns=[f'prob_class_{i}' for i in range(best_epoch_train_probs.shape[1])])\n",
    "    train_prob_df['labels'] = best_epoch_train_labels\n",
    "\n",
    "    val_prob_df = pd.DataFrame(best_epoch_val_probs, columns=[f'prob_class_{i}' for i in range(best_epoch_val_probs.shape[1])])\n",
    "    val_prob_df['labels'] = best_epoch_val_labels\n",
    "\n",
    "    # Save dataframes to Excel\n",
    "    train_prob_df.to_excel(os.path.join(exp_dir,'best_epoch_train_data.xlsx'), index=False)\n",
    "    val_prob_df.to_excel(os.path.join(exp_dir,'best_epoch_val_data.xlsx'), index=False)\n",
    "\n",
    "print('Training Complete !!!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "def train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, num_epochs, scheduler=None, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using device: {device}')\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize best validation loss\n",
    "    best_val_loss = float('inf')\n",
    "    epoch_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch: {epoch + 1}/{num_epochs}')\n",
    "        \n",
    "        start_time = time.time()  # Start epoch timer\n",
    "        \n",
    "        model.train()  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        for batch in train_loader:\n",
    "            category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "            \n",
    "            # Move data to the appropriate device\n",
    "            category_id, subcategory_id = category_id.to(device), subcategory_id.to(device)\n",
    "            ratings, no_of_ratings = ratings.to(device), no_of_ratings.to(device)\n",
    "            actual_price, discount_price = actual_price.to(device), discount_price.to(device)\n",
    "            labels = labels.to(device).long()  # Ensure labels are of type Long\n",
    "            \n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price)\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            \n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update weights\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        # Calculate average training loss\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # Disable gradient computation\n",
    "            for batch in val_loader:\n",
    "                category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "                \n",
    "                # Move data to the appropriate device\n",
    "                category_id, subcategory_id = category_id.to(device), subcategory_id.to(device)\n",
    "                ratings, no_of_ratings = ratings.to(device), no_of_ratings.to(device)\n",
    "                actual_price, discount_price = actual_price.to(device), discount_price.to(device)\n",
    "                labels = labels.to(device).long()  # Ensure labels are of type Long\n",
    "                \n",
    "                outputs = model(category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Calculate average validation loss\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}] | '\n",
    "              f'Train Loss: {train_loss:.4f} | '\n",
    "              f'Val Loss: {val_loss:.4f} | '\n",
    "              f'Epoch Time: {epoch_time:.2f}s')\n",
    "        \n",
    "        # Learning rate scheduler step\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        # Save the best validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epoch_count = 0\n",
    "        else:\n",
    "            epoch_count += 1\n",
    "            \n",
    "        if epoch_count == 30:  # Early stopping if no improvement for 30 epochs\n",
    "            print(f'Validation loss has not improved for {epoch_count} epochs. Training Finished !!!')\n",
    "            break\n",
    "\n",
    "    print('Training Complete !!!')\n",
    "    return best_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:01:24,069] A new study created in memory with name: no-name-aa940287-c29c-41bb-89b5-f5ca29822957\n",
      "C:\\Users\\MKK_Forschung\\AppData\\Local\\Temp\\ipykernel_47776\\2612128501.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "C:\\Users\\MKK_Forschung\\AppData\\Local\\Temp\\ipykernel_47776\\2612128501.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
      "C:\\Users\\MKK_Forschung\\AppData\\Local\\Temp\\ipykernel_47776\\2612128501.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.9369 | Val Loss: 0.8502 | Epoch Time: 2.21s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.8076 | Val Loss: 0.6828 | Epoch Time: 2.40s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.6098 | Val Loss: 0.3728 | Epoch Time: 2.35s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.4148 | Val Loss: 0.2159 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.2996 | Val Loss: 0.1364 | Epoch Time: 2.78s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.2230 | Val Loss: 0.0884 | Epoch Time: 2.75s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.1699 | Val Loss: 0.0583 | Epoch Time: 2.81s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.1298 | Val Loss: 0.0384 | Epoch Time: 2.77s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.1030 | Val Loss: 0.0282 | Epoch Time: 2.75s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:01:49,934] Trial 0 finished with value: 0.020509958700326982 and parameters: {'learning_rate': 0.00010562957598235742, 'weight_decay': 0.000289592173040625, 'dropout_rate': 0.3119535187412517, 'embedding_dim': 100}. Best is trial 0 with value: 0.020509958700326982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0818 | Val Loss: 0.0205 | Epoch Time: 2.73s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.0303 | Val Loss: 1.0182 | Epoch Time: 2.61s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 1.0122 | Val Loss: 1.0016 | Epoch Time: 2.71s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.9925 | Val Loss: 0.9761 | Epoch Time: 2.64s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.9624 | Val Loss: 0.9343 | Epoch Time: 2.66s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.9178 | Val Loss: 0.8802 | Epoch Time: 2.61s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.8711 | Val Loss: 0.8273 | Epoch Time: 2.65s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.8355 | Val Loss: 0.7906 | Epoch Time: 2.61s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.8093 | Val Loss: 0.7617 | Epoch Time: 2.63s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.7817 | Val Loss: 0.7317 | Epoch Time: 2.64s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:02:16,364] Trial 1 finished with value: 0.6969261852002913 and parameters: {'learning_rate': 1.6159744329215897e-05, 'weight_decay': 1.8658325362002914e-05, 'dropout_rate': 0.4963088784095999, 'embedding_dim': 100}. Best is trial 0 with value: 0.020509958700326982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.7605 | Val Loss: 0.6969 | Epoch Time: 2.67s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.0421 | Val Loss: 1.0324 | Epoch Time: 2.66s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 1.0174 | Val Loss: 1.0025 | Epoch Time: 2.65s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.9810 | Val Loss: 0.9608 | Epoch Time: 2.63s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.9397 | Val Loss: 0.9076 | Epoch Time: 2.63s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.8956 | Val Loss: 0.8602 | Epoch Time: 2.66s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.8569 | Val Loss: 0.8222 | Epoch Time: 2.67s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.8279 | Val Loss: 0.7931 | Epoch Time: 2.61s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.8052 | Val Loss: 0.7702 | Epoch Time: 2.68s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.7850 | Val Loss: 0.7493 | Epoch Time: 2.65s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:02:42,764] Trial 2 finished with value: 0.7293243219134629 and parameters: {'learning_rate': 1.2689166795973887e-05, 'weight_decay': 0.0006759529695548365, 'dropout_rate': 0.2031107322958913, 'embedding_dim': 50}. Best is trial 0 with value: 0.020509958700326982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.7685 | Val Loss: 0.7293 | Epoch Time: 2.56s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.9472 | Val Loss: 0.7865 | Epoch Time: 2.54s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.7112 | Val Loss: 0.4968 | Epoch Time: 2.56s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.4833 | Val Loss: 0.2692 | Epoch Time: 2.54s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.3301 | Val Loss: 0.1508 | Epoch Time: 2.64s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.2341 | Val Loss: 0.0921 | Epoch Time: 2.53s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.1793 | Val Loss: 0.0624 | Epoch Time: 2.61s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.1406 | Val Loss: 0.0423 | Epoch Time: 2.56s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.1112 | Val Loss: 0.0260 | Epoch Time: 2.63s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0895 | Val Loss: 0.0191 | Epoch Time: 2.20s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:03:07,807] Trial 3 finished with value: 0.017439396466098486 and parameters: {'learning_rate': 0.00010045004346993516, 'weight_decay': 2.0393872699543215e-05, 'dropout_rate': 0.46642050650031097, 'embedding_dim': 50}. Best is trial 3 with value: 0.017439396466098486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0749 | Val Loss: 0.0174 | Epoch Time: 2.24s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.0351 | Val Loss: 0.9309 | Epoch Time: 2.23s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.8084 | Val Loss: 0.6433 | Epoch Time: 2.25s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.6032 | Val Loss: 0.4600 | Epoch Time: 2.22s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.4820 | Val Loss: 0.3229 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.3831 | Val Loss: 0.2220 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.3041 | Val Loss: 0.1528 | Epoch Time: 2.28s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.2391 | Val Loss: 0.1016 | Epoch Time: 2.21s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.1976 | Val Loss: 0.0758 | Epoch Time: 3.08s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.1722 | Val Loss: 0.0605 | Epoch Time: 3.37s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:03:33,599] Trial 4 finished with value: 0.04853408059646045 and parameters: {'learning_rate': 7.15080976833921e-05, 'weight_decay': 0.0002652587328103737, 'dropout_rate': 0.13884240743713688, 'embedding_dim': 10}. Best is trial 3 with value: 0.017439396466098486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.1508 | Val Loss: 0.0485 | Epoch Time: 3.50s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.0202 | Val Loss: 0.7741 | Epoch Time: 3.38s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.7114 | Val Loss: 0.5342 | Epoch Time: 3.40s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.5349 | Val Loss: 0.3437 | Epoch Time: 3.44s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.4019 | Val Loss: 0.2265 | Epoch Time: 3.41s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.3187 | Val Loss: 0.1582 | Epoch Time: 3.45s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.2618 | Val Loss: 0.1171 | Epoch Time: 3.50s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.2236 | Val Loss: 0.0883 | Epoch Time: 3.43s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.1946 | Val Loss: 0.0685 | Epoch Time: 3.44s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.1681 | Val Loss: 0.0543 | Epoch Time: 3.46s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:04:08,055] Trial 5 finished with value: 0.043829770463328525 and parameters: {'learning_rate': 8.33524983711373e-05, 'weight_decay': 0.00041250724337982503, 'dropout_rate': 0.46726426932482723, 'embedding_dim': 10}. Best is trial 3 with value: 0.017439396466098486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.1499 | Val Loss: 0.0438 | Epoch Time: 3.53s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5242 | Val Loss: 0.0830 | Epoch Time: 3.62s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1366 | Val Loss: 0.0397 | Epoch Time: 3.56s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0903 | Val Loss: 0.0220 | Epoch Time: 3.51s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0779 | Val Loss: 0.0233 | Epoch Time: 3.49s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0638 | Val Loss: 0.0432 | Epoch Time: 3.14s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0537 | Val Loss: 0.0106 | Epoch Time: 2.22s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0440 | Val Loss: 0.0118 | Epoch Time: 2.20s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0365 | Val Loss: 0.0190 | Epoch Time: 2.24s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0358 | Val Loss: 0.0130 | Epoch Time: 2.24s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:04:36,542] Trial 6 finished with value: 0.010608071051049797 and parameters: {'learning_rate': 0.0013494612702106877, 'weight_decay': 4.833582743361429e-05, 'dropout_rate': 0.32411321536979343, 'embedding_dim': 100}. Best is trial 6 with value: 0.010608071051049797.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0338 | Val Loss: 0.0937 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4203 | Val Loss: 0.0923 | Epoch Time: 2.25s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1261 | Val Loss: 0.0457 | Epoch Time: 2.20s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0709 | Val Loss: 0.0192 | Epoch Time: 2.23s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0560 | Val Loss: 0.0237 | Epoch Time: 2.23s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0468 | Val Loss: 0.0127 | Epoch Time: 2.24s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0473 | Val Loss: 0.0426 | Epoch Time: 2.22s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0377 | Val Loss: 0.0086 | Epoch Time: 2.25s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0276 | Val Loss: 0.0082 | Epoch Time: 2.22s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0257 | Val Loss: 0.0095 | Epoch Time: 2.23s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:04:58,842] Trial 7 finished with value: 0.008174357079100915 and parameters: {'learning_rate': 0.0019670874265759423, 'weight_decay': 7.364732309918615e-05, 'dropout_rate': 0.37242835482197756, 'embedding_dim': 100}. Best is trial 7 with value: 0.008174357079100915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0215 | Val Loss: 0.0126 | Epoch Time: 2.22s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2038 | Val Loss: 0.0193 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0522 | Val Loss: 0.0236 | Epoch Time: 2.24s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0474 | Val Loss: 0.0209 | Epoch Time: 2.23s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0486 | Val Loss: 0.0198 | Epoch Time: 2.20s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0465 | Val Loss: 0.0154 | Epoch Time: 2.21s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0450 | Val Loss: 0.0238 | Epoch Time: 2.22s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0418 | Val Loss: 0.0177 | Epoch Time: 2.19s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0395 | Val Loss: 0.0116 | Epoch Time: 2.21s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0391 | Val Loss: 0.0091 | Epoch Time: 2.22s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:05:21,080] Trial 8 finished with value: 0.009098814622629233 and parameters: {'learning_rate': 0.0025998655131711087, 'weight_decay': 0.0033943396741760276, 'dropout_rate': 0.41472363976351223, 'embedding_dim': 10}. Best is trial 7 with value: 0.008174357079100915.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0390 | Val Loss: 0.0166 | Epoch Time: 2.23s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3560 | Val Loss: 0.0479 | Epoch Time: 2.25s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0576 | Val Loss: 0.0191 | Epoch Time: 2.20s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0420 | Val Loss: 0.0185 | Epoch Time: 2.20s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0363 | Val Loss: 0.0110 | Epoch Time: 2.21s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0320 | Val Loss: 0.0183 | Epoch Time: 2.24s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0302 | Val Loss: 0.0186 | Epoch Time: 2.20s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0287 | Val Loss: 0.0146 | Epoch Time: 2.24s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0258 | Val Loss: 0.0104 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0266 | Val Loss: 0.0078 | Epoch Time: 2.27s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:05:43,411] Trial 9 finished with value: 0.007788043300122378 and parameters: {'learning_rate': 0.0012493258966219426, 'weight_decay': 0.0016894579600223029, 'dropout_rate': 0.43299503513824733, 'embedding_dim': 50}. Best is trial 9 with value: 0.007788043300122378.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0253 | Val Loss: 0.0134 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2234 | Val Loss: 0.0711 | Epoch Time: 2.34s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0927 | Val Loss: 0.0657 | Epoch Time: 2.36s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0888 | Val Loss: 0.0419 | Epoch Time: 2.31s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0932 | Val Loss: 0.1481 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0893 | Val Loss: 0.0434 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0887 | Val Loss: 0.0525 | Epoch Time: 2.31s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0834 | Val Loss: 0.0339 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0875 | Val Loss: 0.0471 | Epoch Time: 2.34s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0874 | Val Loss: 0.0389 | Epoch Time: 2.30s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:06:06,634] Trial 10 finished with value: 0.033903788364622545 and parameters: {'learning_rate': 0.009024814057342088, 'weight_decay': 0.009921214886711662, 'dropout_rate': 0.2179574984453195, 'embedding_dim': 50}. Best is trial 9 with value: 0.007788043300122378.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0919 | Val Loss: 0.0522 | Epoch Time: 2.30s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4725 | Val Loss: 0.0746 | Epoch Time: 2.23s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0928 | Val Loss: 0.0151 | Epoch Time: 2.22s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0553 | Val Loss: 0.0155 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0453 | Val Loss: 0.0082 | Epoch Time: 2.20s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0334 | Val Loss: 0.0095 | Epoch Time: 2.19s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0330 | Val Loss: 0.0087 | Epoch Time: 2.18s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0274 | Val Loss: 0.0103 | Epoch Time: 2.20s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0273 | Val Loss: 0.0062 | Epoch Time: 2.25s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0246 | Val Loss: 0.0155 | Epoch Time: 2.19s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:06:28,732] Trial 11 finished with value: 0.006220188043962773 and parameters: {'learning_rate': 0.0009292908424582042, 'weight_decay': 0.001186952136817461, 'dropout_rate': 0.3751717641485347, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0229 | Val Loss: 0.0094 | Epoch Time: 2.23s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4726 | Val Loss: 0.1192 | Epoch Time: 2.22s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0992 | Val Loss: 0.0214 | Epoch Time: 2.24s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0465 | Val Loss: 0.0144 | Epoch Time: 2.23s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0370 | Val Loss: 0.0137 | Epoch Time: 2.24s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0318 | Val Loss: 0.0105 | Epoch Time: 2.18s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0297 | Val Loss: 0.0142 | Epoch Time: 2.21s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0295 | Val Loss: 0.0090 | Epoch Time: 2.20s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0283 | Val Loss: 0.0100 | Epoch Time: 2.19s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0258 | Val Loss: 0.0086 | Epoch Time: 2.21s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:06:50,878] Trial 12 finished with value: 0.008553036597419045 and parameters: {'learning_rate': 0.0007361865278592217, 'weight_decay': 0.0014866829890175365, 'dropout_rate': 0.3886087389983241, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0252 | Val Loss: 0.0094 | Epoch Time: 2.22s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.6563 | Val Loss: 0.1927 | Epoch Time: 2.30s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1643 | Val Loss: 0.0308 | Epoch Time: 2.23s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0744 | Val Loss: 0.0187 | Epoch Time: 2.18s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0476 | Val Loss: 0.0120 | Epoch Time: 2.24s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0426 | Val Loss: 0.0111 | Epoch Time: 2.23s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0401 | Val Loss: 0.0123 | Epoch Time: 2.21s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0335 | Val Loss: 0.0137 | Epoch Time: 2.14s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0340 | Val Loss: 0.0101 | Epoch Time: 2.20s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0313 | Val Loss: 0.0097 | Epoch Time: 2.19s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:07:12,995] Trial 13 finished with value: 0.009677278544185482 and parameters: {'learning_rate': 0.00038630428424601834, 'weight_decay': 0.002390813889571911, 'dropout_rate': 0.4186222564335113, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0303 | Val Loss: 0.0113 | Epoch Time: 2.19s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2281 | Val Loss: 0.0325 | Epoch Time: 2.26s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0771 | Val Loss: 0.0393 | Epoch Time: 2.21s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0710 | Val Loss: 0.0331 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0682 | Val Loss: 0.0263 | Epoch Time: 2.21s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0672 | Val Loss: 0.0311 | Epoch Time: 2.17s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0653 | Val Loss: 0.0278 | Epoch Time: 2.17s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0678 | Val Loss: 0.0589 | Epoch Time: 2.19s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0708 | Val Loss: 0.0297 | Epoch Time: 2.21s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0643 | Val Loss: 0.0238 | Epoch Time: 2.20s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:07:35,393] Trial 14 finished with value: 0.023788819672860284 and parameters: {'learning_rate': 0.0062400712799435985, 'weight_decay': 0.0068237581477349095, 'dropout_rate': 0.34733086664921575, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0690 | Val Loss: 0.0299 | Epoch Time: 2.57s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7554 | Val Loss: 0.2408 | Epoch Time: 2.48s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.2176 | Val Loss: 0.0466 | Epoch Time: 2.55s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0944 | Val Loss: 0.0216 | Epoch Time: 2.64s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0585 | Val Loss: 0.0105 | Epoch Time: 2.63s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0426 | Val Loss: 0.0104 | Epoch Time: 2.66s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0331 | Val Loss: 0.0107 | Epoch Time: 2.62s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0269 | Val Loss: 0.0072 | Epoch Time: 2.60s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0270 | Val Loss: 0.0063 | Epoch Time: 2.66s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0252 | Val Loss: 0.0082 | Epoch Time: 2.62s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:08:01,572] Trial 15 finished with value: 0.006307462766242053 and parameters: {'learning_rate': 0.00036492282440902824, 'weight_decay': 0.0007996090080089972, 'dropout_rate': 0.24606338835340505, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0244 | Val Loss: 0.0068 | Epoch Time: 2.69s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7771 | Val Loss: 0.3860 | Epoch Time: 2.74s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.2752 | Val Loss: 0.0806 | Epoch Time: 2.71s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1284 | Val Loss: 0.0302 | Epoch Time: 2.64s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0743 | Val Loss: 0.0158 | Epoch Time: 2.62s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0511 | Val Loss: 0.0117 | Epoch Time: 2.66s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0399 | Val Loss: 0.0116 | Epoch Time: 2.70s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0308 | Val Loss: 0.0071 | Epoch Time: 2.68s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0274 | Val Loss: 0.0063 | Epoch Time: 2.65s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0260 | Val Loss: 0.0088 | Epoch Time: 2.66s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:08:28,302] Trial 16 finished with value: 0.00632432877491053 and parameters: {'learning_rate': 0.00028503395300751965, 'weight_decay': 0.0007879309245198366, 'dropout_rate': 0.25729186350224653, 'embedding_dim': 50}. Best is trial 11 with value: 0.006220188043962773.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0251 | Val Loss: 0.0078 | Epoch Time: 2.65s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7743 | Val Loss: 0.4307 | Epoch Time: 2.74s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.3196 | Val Loss: 0.0840 | Epoch Time: 2.74s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1443 | Val Loss: 0.0336 | Epoch Time: 2.59s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0782 | Val Loss: 0.0165 | Epoch Time: 2.56s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0505 | Val Loss: 0.0096 | Epoch Time: 2.63s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0388 | Val Loss: 0.0070 | Epoch Time: 2.65s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0304 | Val Loss: 0.0056 | Epoch Time: 2.61s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0272 | Val Loss: 0.0058 | Epoch Time: 2.68s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0225 | Val Loss: 0.0049 | Epoch Time: 2.62s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:08:54,686] Trial 17 finished with value: 0.0049137186959009715 and parameters: {'learning_rate': 0.00037638791792994077, 'weight_decay': 9.443191008391016e-05, 'dropout_rate': 0.25596179173798705, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0283 | Val Loss: 0.0057 | Epoch Time: 2.54s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2476 | Val Loss: 0.0280 | Epoch Time: 2.45s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0607 | Val Loss: 0.0397 | Epoch Time: 2.43s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0375 | Val Loss: 0.0228 | Epoch Time: 2.46s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0312 | Val Loss: 0.0133 | Epoch Time: 2.45s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0219 | Val Loss: 0.0090 | Epoch Time: 2.35s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0207 | Val Loss: 0.0106 | Epoch Time: 2.33s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0181 | Val Loss: 0.0079 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0151 | Val Loss: 0.0101 | Epoch Time: 2.35s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0156 | Val Loss: 0.0086 | Epoch Time: 2.37s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:09:18,515] Trial 18 finished with value: 0.006598479979030706 and parameters: {'learning_rate': 0.003709204287299474, 'weight_decay': 0.00011127944824139722, 'dropout_rate': 0.11859608504555447, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0127 | Val Loss: 0.0066 | Epoch Time: 2.31s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7333 | Val Loss: 0.4534 | Epoch Time: 2.34s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.3944 | Val Loss: 0.1775 | Epoch Time: 2.35s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.2294 | Val Loss: 0.0837 | Epoch Time: 2.33s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.1668 | Val Loss: 0.0491 | Epoch Time: 2.33s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.1205 | Val Loss: 0.0303 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0960 | Val Loss: 0.0227 | Epoch Time: 2.32s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0792 | Val Loss: 0.0151 | Epoch Time: 2.31s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0688 | Val Loss: 0.0134 | Epoch Time: 2.32s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0563 | Val Loss: 0.0117 | Epoch Time: 2.30s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:09:41,740] Trial 19 finished with value: 0.011614463500483263 and parameters: {'learning_rate': 0.00021538054460256987, 'weight_decay': 0.00013621375998289033, 'dropout_rate': 0.27551366179307546, 'embedding_dim': 10}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0492 | Val Loss: 0.0116 | Epoch Time: 2.30s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.9563 | Val Loss: 0.8707 | Epoch Time: 2.33s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.8308 | Val Loss: 0.7699 | Epoch Time: 2.32s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.7641 | Val Loss: 0.7091 | Epoch Time: 2.33s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.7053 | Val Loss: 0.6416 | Epoch Time: 2.32s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.6454 | Val Loss: 0.5714 | Epoch Time: 2.34s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.5858 | Val Loss: 0.4997 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.5309 | Val Loss: 0.4370 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.4808 | Val Loss: 0.3842 | Epoch Time: 2.34s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.4362 | Val Loss: 0.3369 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:10:04,962] Trial 20 finished with value: 0.2974209585177001 and parameters: {'learning_rate': 3.632027312738742e-05, 'weight_decay': 3.9639957756065846e-05, 'dropout_rate': 0.15874985705339217, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.3962 | Val Loss: 0.2974 | Epoch Time: 2.30s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.6196 | Val Loss: 0.1123 | Epoch Time: 2.31s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1284 | Val Loss: 0.0241 | Epoch Time: 2.31s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0594 | Val Loss: 0.0148 | Epoch Time: 2.31s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0446 | Val Loss: 0.0108 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0348 | Val Loss: 0.0088 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0323 | Val Loss: 0.0094 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0305 | Val Loss: 0.0092 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0273 | Val Loss: 0.0085 | Epoch Time: 2.30s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0275 | Val Loss: 0.0085 | Epoch Time: 2.31s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:10:28,045] Trial 21 finished with value: 0.008459858339397558 and parameters: {'learning_rate': 0.0004934996861845533, 'weight_decay': 0.0009122651458093245, 'dropout_rate': 0.23661685433949456, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0247 | Val Loss: 0.0115 | Epoch Time: 2.31s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4887 | Val Loss: 0.0684 | Epoch Time: 2.33s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1105 | Val Loss: 0.0193 | Epoch Time: 2.33s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0548 | Val Loss: 0.0152 | Epoch Time: 2.30s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0439 | Val Loss: 0.0143 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0378 | Val Loss: 0.0167 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0326 | Val Loss: 0.0073 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0340 | Val Loss: 0.0080 | Epoch Time: 2.29s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0290 | Val Loss: 0.0056 | Epoch Time: 2.32s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0343 | Val Loss: 0.0074 | Epoch Time: 2.31s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:10:51,165] Trial 22 finished with value: 0.005595560665247459 and parameters: {'learning_rate': 0.0006779228621256484, 'weight_decay': 0.00020694375290597635, 'dropout_rate': 0.18498356965183277, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0280 | Val Loss: 0.0068 | Epoch Time: 2.32s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4905 | Val Loss: 0.0777 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0964 | Val Loss: 0.0192 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0536 | Val Loss: 0.0166 | Epoch Time: 2.31s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0454 | Val Loss: 0.0702 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0355 | Val Loss: 0.0091 | Epoch Time: 2.30s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0344 | Val Loss: 0.0102 | Epoch Time: 2.32s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0388 | Val Loss: 0.0147 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0349 | Val Loss: 0.0103 | Epoch Time: 2.31s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0332 | Val Loss: 0.0120 | Epoch Time: 2.31s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:11:14,232] Trial 23 finished with value: 0.009075909813315863 and parameters: {'learning_rate': 0.0008807478986313402, 'weight_decay': 0.00016153032700362758, 'dropout_rate': 0.1902475012458476, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0270 | Val Loss: 0.0218 | Epoch Time: 2.30s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.8606 | Val Loss: 0.7638 | Epoch Time: 2.35s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.6506 | Val Loss: 0.3560 | Epoch Time: 2.33s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.3677 | Val Loss: 0.1543 | Epoch Time: 2.33s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.2212 | Val Loss: 0.0725 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.1493 | Val Loss: 0.0397 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.1032 | Val Loss: 0.0252 | Epoch Time: 2.29s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0746 | Val Loss: 0.0155 | Epoch Time: 2.33s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0587 | Val Loss: 0.0131 | Epoch Time: 2.34s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0476 | Val Loss: 0.0142 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:11:37,455] Trial 24 finished with value: 0.011740144591522528 and parameters: {'learning_rate': 0.00018521500035191435, 'weight_decay': 1.0030688724755636e-05, 'dropout_rate': 0.28347437501492667, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0401 | Val Loss: 0.0117 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.6467 | Val Loss: 0.1311 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1446 | Val Loss: 0.0282 | Epoch Time: 2.34s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0697 | Val Loss: 0.0202 | Epoch Time: 2.36s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0493 | Val Loss: 0.0158 | Epoch Time: 2.34s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0422 | Val Loss: 0.0098 | Epoch Time: 2.33s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0344 | Val Loss: 0.0094 | Epoch Time: 2.34s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0307 | Val Loss: 0.0133 | Epoch Time: 2.35s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0281 | Val Loss: 0.0121 | Epoch Time: 2.34s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0317 | Val Loss: 0.0135 | Epoch Time: 2.29s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:12:00,761] Trial 25 finished with value: 0.008712026447654508 and parameters: {'learning_rate': 0.0006179621261351598, 'weight_decay': 0.00042132897539118395, 'dropout_rate': 0.18019633931215823, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0261 | Val Loss: 0.0087 | Epoch Time: 2.32s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5017 | Val Loss: 0.1179 | Epoch Time: 2.31s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1201 | Val Loss: 0.0250 | Epoch Time: 2.32s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0718 | Val Loss: 0.0156 | Epoch Time: 2.31s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0595 | Val Loss: 0.0144 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0494 | Val Loss: 0.0096 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0445 | Val Loss: 0.0158 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0434 | Val Loss: 0.0061 | Epoch Time: 2.31s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0390 | Val Loss: 0.0141 | Epoch Time: 2.31s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0357 | Val Loss: 0.0071 | Epoch Time: 2.33s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:12:23,872] Trial 26 finished with value: 0.006078647465103366 and parameters: {'learning_rate': 0.0012320679137982518, 'weight_decay': 7.978448299603688e-05, 'dropout_rate': 0.10233335368277638, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0233 | Val Loss: 0.0172 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3221 | Val Loss: 0.0249 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0695 | Val Loss: 0.0228 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0384 | Val Loss: 0.0113 | Epoch Time: 2.28s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0335 | Val Loss: 0.0178 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0290 | Val Loss: 0.0196 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0197 | Val Loss: 0.0216 | Epoch Time: 2.34s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0220 | Val Loss: 0.0132 | Epoch Time: 2.35s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0163 | Val Loss: 0.0128 | Epoch Time: 2.32s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0202 | Val Loss: 0.0076 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:12:46,966] Trial 27 finished with value: 0.007553130291266678 and parameters: {'learning_rate': 0.0035777137875069856, 'weight_decay': 6.326545523655814e-05, 'dropout_rate': 0.1175589900828227, 'embedding_dim': 50}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0158 | Val Loss: 0.0094 | Epoch Time: 2.31s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.8947 | Val Loss: 0.7730 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.7538 | Val Loss: 0.6891 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.6340 | Val Loss: 0.4532 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.4060 | Val Loss: 0.2099 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.2482 | Val Loss: 0.1023 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.1628 | Val Loss: 0.0592 | Epoch Time: 2.32s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.1124 | Val Loss: 0.0374 | Epoch Time: 2.33s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0810 | Val Loss: 0.0237 | Epoch Time: 2.30s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0639 | Val Loss: 0.0163 | Epoch Time: 2.31s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:13:09,995] Trial 28 finished with value: 0.0163363453253643 and parameters: {'learning_rate': 0.0001630855185792264, 'weight_decay': 0.00019597703721098956, 'dropout_rate': 0.10377971956414209, 'embedding_dim': 100}. Best is trial 17 with value: 0.0049137186959009715.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0525 | Val Loss: 0.0167 | Epoch Time: 2.32s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3451 | Val Loss: 0.0268 | Epoch Time: 2.24s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0580 | Val Loss: 0.0063 | Epoch Time: 2.17s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0377 | Val Loss: 0.0100 | Epoch Time: 2.15s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0253 | Val Loss: 0.0107 | Epoch Time: 2.16s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0232 | Val Loss: 0.0246 | Epoch Time: 2.20s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0202 | Val Loss: 0.0088 | Epoch Time: 2.19s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0218 | Val Loss: 0.0038 | Epoch Time: 2.19s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0173 | Val Loss: 0.0066 | Epoch Time: 2.20s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0191 | Val Loss: 0.0070 | Epoch Time: 2.19s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:13:31,913] Trial 29 finished with value: 0.003819821802764675 and parameters: {'learning_rate': 0.0014260236839837505, 'weight_decay': 9.791564210886598e-05, 'dropout_rate': 0.16360835321441344, 'embedding_dim': 10}. Best is trial 29 with value: 0.003819821802764675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0165 | Val Loss: 0.0087 | Epoch Time: 2.21s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2640 | Val Loss: 0.0312 | Epoch Time: 2.37s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0579 | Val Loss: 0.0171 | Epoch Time: 2.75s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0432 | Val Loss: 0.0152 | Epoch Time: 2.73s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0304 | Val Loss: 0.0065 | Epoch Time: 2.75s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0286 | Val Loss: 0.0068 | Epoch Time: 2.84s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0281 | Val Loss: 0.0094 | Epoch Time: 2.81s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0245 | Val Loss: 0.0134 | Epoch Time: 2.75s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0248 | Val Loss: 0.0078 | Epoch Time: 2.76s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0208 | Val Loss: 0.0071 | Epoch Time: 2.75s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:13:59,235] Trial 30 finished with value: 0.006485728087926706 and parameters: {'learning_rate': 0.001839824572537461, 'weight_decay': 3.051919042087296e-05, 'dropout_rate': 0.1679391044134922, 'embedding_dim': 10}. Best is trial 29 with value: 0.003819821802764675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0205 | Val Loss: 0.0095 | Epoch Time: 2.79s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3184 | Val Loss: 0.0238 | Epoch Time: 2.76s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0652 | Val Loss: 0.0168 | Epoch Time: 2.67s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0424 | Val Loss: 0.0147 | Epoch Time: 2.70s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0328 | Val Loss: 0.0139 | Epoch Time: 2.64s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0270 | Val Loss: 0.0096 | Epoch Time: 2.60s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0253 | Val Loss: 0.0097 | Epoch Time: 2.62s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0212 | Val Loss: 0.0050 | Epoch Time: 2.64s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0204 | Val Loss: 0.0061 | Epoch Time: 2.67s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0192 | Val Loss: 0.0042 | Epoch Time: 2.66s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:14:25,811] Trial 31 finished with value: 0.004219920686355963 and parameters: {'learning_rate': 0.0012363533415283854, 'weight_decay': 8.769073824257748e-05, 'dropout_rate': 0.14291045265665187, 'embedding_dim': 10}. Best is trial 29 with value: 0.003819821802764675.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0213 | Val Loss: 0.0065 | Epoch Time: 2.61s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5325 | Val Loss: 0.1162 | Epoch Time: 2.69s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1635 | Val Loss: 0.0316 | Epoch Time: 2.79s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0888 | Val Loss: 0.0169 | Epoch Time: 2.77s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0571 | Val Loss: 0.0085 | Epoch Time: 2.52s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0443 | Val Loss: 0.0100 | Epoch Time: 2.68s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0357 | Val Loss: 0.0061 | Epoch Time: 2.62s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0304 | Val Loss: 0.0053 | Epoch Time: 2.67s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0251 | Val Loss: 0.0044 | Epoch Time: 2.60s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0244 | Val Loss: 0.0065 | Epoch Time: 2.64s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:14:52,483] Trial 32 finished with value: 0.003094467500759688 and parameters: {'learning_rate': 0.00047307239371176485, 'weight_decay': 0.0002572176180532664, 'dropout_rate': 0.1475648189305909, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0192 | Val Loss: 0.0031 | Epoch Time: 2.69s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7421 | Val Loss: 0.3652 | Epoch Time: 2.50s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.2973 | Val Loss: 0.0880 | Epoch Time: 2.55s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1574 | Val Loss: 0.0392 | Epoch Time: 2.55s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.1036 | Val Loss: 0.0199 | Epoch Time: 2.55s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0722 | Val Loss: 0.0149 | Epoch Time: 2.29s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0572 | Val Loss: 0.0105 | Epoch Time: 2.22s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0480 | Val Loss: 0.0092 | Epoch Time: 2.17s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0403 | Val Loss: 0.0075 | Epoch Time: 2.23s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0352 | Val Loss: 0.0070 | Epoch Time: 2.17s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:15:15,923] Trial 33 finished with value: 0.007016204209761664 and parameters: {'learning_rate': 0.0003102430956169279, 'weight_decay': 0.00010696255522251537, 'dropout_rate': 0.1490623134306614, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0314 | Val Loss: 0.0074 | Epoch Time: 2.20s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.1558 | Val Loss: 1.0643 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.9035 | Val Loss: 0.7851 | Epoch Time: 2.29s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.7628 | Val Loss: 0.7090 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.7021 | Val Loss: 0.6502 | Epoch Time: 2.30s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.6492 | Val Loss: 0.5819 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.5840 | Val Loss: 0.4766 | Epoch Time: 2.31s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.4962 | Val Loss: 0.3645 | Epoch Time: 2.33s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.4208 | Val Loss: 0.2889 | Epoch Time: 2.37s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.3748 | Val Loss: 0.2410 | Epoch Time: 2.34s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:15:39,079] Trial 34 finished with value: 0.20130375079730506 and parameters: {'learning_rate': 5.2724088910489585e-05, 'weight_decay': 0.0003747915074220714, 'dropout_rate': 0.21459654350000412, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.3324 | Val Loss: 0.2013 | Epoch Time: 2.33s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5180 | Val Loss: 0.1245 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1498 | Val Loss: 0.0317 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0782 | Val Loss: 0.0156 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0536 | Val Loss: 0.0115 | Epoch Time: 2.26s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0399 | Val Loss: 0.0092 | Epoch Time: 2.22s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0350 | Val Loss: 0.0103 | Epoch Time: 2.27s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0304 | Val Loss: 0.0081 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0266 | Val Loss: 0.0063 | Epoch Time: 2.29s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0258 | Val Loss: 0.0068 | Epoch Time: 2.27s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:16:01,736] Trial 35 finished with value: 0.006265898984252921 and parameters: {'learning_rate': 0.0004948217391484498, 'weight_decay': 2.5013788911678066e-05, 'dropout_rate': 0.13001878127015376, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0215 | Val Loss: 0.0063 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.8380 | Val Loss: 0.5605 | Epoch Time: 2.26s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.4913 | Val Loss: 0.2527 | Epoch Time: 2.24s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.2943 | Val Loss: 0.1087 | Epoch Time: 2.27s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.2015 | Val Loss: 0.0660 | Epoch Time: 2.33s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.1583 | Val Loss: 0.0432 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.1260 | Val Loss: 0.0348 | Epoch Time: 2.35s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.1017 | Val Loss: 0.0226 | Epoch Time: 2.29s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0859 | Val Loss: 0.0164 | Epoch Time: 2.31s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0705 | Val Loss: 0.0135 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:16:24,771] Trial 36 finished with value: 0.013170695088813782 and parameters: {'learning_rate': 0.0001407800327769612, 'weight_decay': 0.0002944291575350586, 'dropout_rate': 0.14226662335276644, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0640 | Val Loss: 0.0132 | Epoch Time: 2.35s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2623 | Val Loss: 0.0211 | Epoch Time: 2.25s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0515 | Val Loss: 0.0226 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0368 | Val Loss: 0.0184 | Epoch Time: 2.28s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0334 | Val Loss: 0.0090 | Epoch Time: 2.23s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0263 | Val Loss: 0.0084 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0240 | Val Loss: 0.0084 | Epoch Time: 2.21s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0202 | Val Loss: 0.0087 | Epoch Time: 2.24s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0197 | Val Loss: 0.0086 | Epoch Time: 2.23s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0155 | Val Loss: 0.0105 | Epoch Time: 2.20s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:16:47,169] Trial 37 finished with value: 0.005871245736267567 and parameters: {'learning_rate': 0.0018755189770935951, 'weight_decay': 5.358107052935618e-05, 'dropout_rate': 0.31488798732654266, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0158 | Val Loss: 0.0059 | Epoch Time: 2.21s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.9761 | Val Loss: 0.9621 | Epoch Time: 2.20s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.9462 | Val Loss: 0.9161 | Epoch Time: 2.22s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.8818 | Val Loss: 0.8141 | Epoch Time: 2.31s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.7881 | Val Loss: 0.6926 | Epoch Time: 2.23s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.7041 | Val Loss: 0.5870 | Epoch Time: 2.23s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.6338 | Val Loss: 0.5026 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.5823 | Val Loss: 0.4406 | Epoch Time: 2.31s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.5390 | Val Loss: 0.3918 | Epoch Time: 2.39s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.4977 | Val Loss: 0.3505 | Epoch Time: 2.26s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:17:09,964] Trial 38 finished with value: 0.3143370818867478 and parameters: {'learning_rate': 2.4625552669229523e-05, 'weight_decay': 1.4381796860198054e-05, 'dropout_rate': 0.19871053547545448, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.4657 | Val Loss: 0.3143 | Epoch Time: 2.33s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2115 | Val Loss: 0.0227 | Epoch Time: 2.20s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0423 | Val Loss: 0.0143 | Epoch Time: 2.18s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0293 | Val Loss: 0.0141 | Epoch Time: 2.18s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0277 | Val Loss: 0.0160 | Epoch Time: 2.13s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0247 | Val Loss: 0.0062 | Epoch Time: 2.14s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0212 | Val Loss: 0.0066 | Epoch Time: 2.16s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0188 | Val Loss: 0.0159 | Epoch Time: 2.13s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0198 | Val Loss: 0.0056 | Epoch Time: 2.12s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0179 | Val Loss: 0.0116 | Epoch Time: 2.14s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:17:31,499] Trial 39 finished with value: 0.005623533833513452 and parameters: {'learning_rate': 0.0031517426381495453, 'weight_decay': 0.0005288692446644604, 'dropout_rate': 0.1665344050235399, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0188 | Val Loss: 0.0072 | Epoch Time: 2.14s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5153 | Val Loss: 0.0854 | Epoch Time: 2.24s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1392 | Val Loss: 0.0416 | Epoch Time: 2.56s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0883 | Val Loss: 0.0218 | Epoch Time: 2.38s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0717 | Val Loss: 0.0657 | Epoch Time: 2.36s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0556 | Val Loss: 0.0249 | Epoch Time: 2.42s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0596 | Val Loss: 0.0138 | Epoch Time: 2.40s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0497 | Val Loss: 0.0110 | Epoch Time: 2.42s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0487 | Val Loss: 0.0102 | Epoch Time: 2.33s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0438 | Val Loss: 0.0218 | Epoch Time: 2.41s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:17:55,508] Trial 40 finished with value: 0.010191388807969258 and parameters: {'learning_rate': 0.001122330358151574, 'weight_decay': 9.724397820185539e-05, 'dropout_rate': 0.22877787528299584, 'embedding_dim': 100}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0416 | Val Loss: 0.0188 | Epoch Time: 2.47s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5788 | Val Loss: 0.1009 | Epoch Time: 2.44s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1605 | Val Loss: 0.0283 | Epoch Time: 2.55s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0805 | Val Loss: 0.0222 | Epoch Time: 2.47s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0537 | Val Loss: 0.0159 | Epoch Time: 2.30s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0386 | Val Loss: 0.0108 | Epoch Time: 2.25s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0356 | Val Loss: 0.0154 | Epoch Time: 2.16s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0284 | Val Loss: 0.0138 | Epoch Time: 2.18s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0269 | Val Loss: 0.0119 | Epoch Time: 2.17s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0241 | Val Loss: 0.0077 | Epoch Time: 2.20s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:18:18,419] Trial 41 finished with value: 0.007706697572190336 and parameters: {'learning_rate': 0.0005932348477023255, 'weight_decay': 0.00022082509147348543, 'dropout_rate': 0.18000633612550965, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0219 | Val Loss: 0.0078 | Epoch Time: 2.20s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3511 | Val Loss: 0.0268 | Epoch Time: 2.18s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0566 | Val Loss: 0.0165 | Epoch Time: 2.18s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0347 | Val Loss: 0.0192 | Epoch Time: 2.16s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0300 | Val Loss: 0.0147 | Epoch Time: 2.21s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0228 | Val Loss: 0.0105 | Epoch Time: 2.18s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0244 | Val Loss: 0.0082 | Epoch Time: 2.20s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0196 | Val Loss: 0.0058 | Epoch Time: 2.15s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0185 | Val Loss: 0.0078 | Epoch Time: 2.14s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0183 | Val Loss: 0.0039 | Epoch Time: 2.17s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:18:40,195] Trial 42 finished with value: 0.003927646935632658 and parameters: {'learning_rate': 0.0015823780460933828, 'weight_decay': 0.00019748976192185435, 'dropout_rate': 0.21278612143833114, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0166 | Val Loss: 0.0148 | Epoch Time: 2.19s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2605 | Val Loss: 0.0375 | Epoch Time: 2.20s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0578 | Val Loss: 0.0113 | Epoch Time: 2.20s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0398 | Val Loss: 0.0112 | Epoch Time: 2.23s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0298 | Val Loss: 0.0132 | Epoch Time: 2.25s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0255 | Val Loss: 0.0073 | Epoch Time: 2.26s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0240 | Val Loss: 0.0079 | Epoch Time: 2.26s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0206 | Val Loss: 0.0067 | Epoch Time: 2.27s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0202 | Val Loss: 0.0060 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0169 | Val Loss: 0.0140 | Epoch Time: 2.28s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:19:02,733] Trial 43 finished with value: 0.00596427626687141 and parameters: {'learning_rate': 0.0016668075172016855, 'weight_decay': 0.00014083832157778278, 'dropout_rate': 0.21470959847541438, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0167 | Val Loss: 0.0063 | Epoch Time: 2.31s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2451 | Val Loss: 0.0231 | Epoch Time: 2.18s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0527 | Val Loss: 0.0113 | Epoch Time: 2.10s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0367 | Val Loss: 0.0118 | Epoch Time: 2.15s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0288 | Val Loss: 0.0167 | Epoch Time: 2.14s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0243 | Val Loss: 0.0082 | Epoch Time: 2.14s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0221 | Val Loss: 0.0087 | Epoch Time: 2.12s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0207 | Val Loss: 0.0085 | Epoch Time: 2.11s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0195 | Val Loss: 0.0078 | Epoch Time: 2.13s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0194 | Val Loss: 0.0088 | Epoch Time: 2.14s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:19:24,151] Trial 44 finished with value: 0.005938462335042684 and parameters: {'learning_rate': 0.002761256722580868, 'weight_decay': 3.8818277121872636e-05, 'dropout_rate': 0.26229557063923187, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0189 | Val Loss: 0.0059 | Epoch Time: 2.19s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.1893 | Val Loss: 0.0366 | Epoch Time: 2.19s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0463 | Val Loss: 0.0304 | Epoch Time: 2.21s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0288 | Val Loss: 0.0141 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0265 | Val Loss: 0.0129 | Epoch Time: 2.25s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0223 | Val Loss: 0.0074 | Epoch Time: 2.59s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0194 | Val Loss: 0.0058 | Epoch Time: 2.75s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0191 | Val Loss: 0.0089 | Epoch Time: 2.71s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0177 | Val Loss: 0.0106 | Epoch Time: 2.74s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0158 | Val Loss: 0.0098 | Epoch Time: 2.74s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:19:49,401] Trial 45 finished with value: 0.0057985063418669516 and parameters: {'learning_rate': 0.005179834289826272, 'weight_decay': 7.927963251216913e-05, 'dropout_rate': 0.13326396674324498, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0151 | Val Loss: 0.0195 | Epoch Time: 2.82s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4198 | Val Loss: 0.0465 | Epoch Time: 2.80s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0793 | Val Loss: 0.0243 | Epoch Time: 2.77s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0434 | Val Loss: 0.0156 | Epoch Time: 2.75s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0329 | Val Loss: 0.0097 | Epoch Time: 2.80s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0263 | Val Loss: 0.0051 | Epoch Time: 2.80s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0234 | Val Loss: 0.0046 | Epoch Time: 2.75s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0215 | Val Loss: 0.0075 | Epoch Time: 2.79s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0197 | Val Loss: 0.0048 | Epoch Time: 2.79s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0204 | Val Loss: 0.0155 | Epoch Time: 2.71s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:20:17,124] Trial 46 finished with value: 0.004643068095178297 and parameters: {'learning_rate': 0.0009777827060141514, 'weight_decay': 0.00015809552805283163, 'dropout_rate': 0.20542594222226002, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0172 | Val Loss: 0.0089 | Epoch Time: 2.75s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3773 | Val Loss: 0.0260 | Epoch Time: 2.76s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0670 | Val Loss: 0.0108 | Epoch Time: 2.76s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0368 | Val Loss: 0.0126 | Epoch Time: 2.81s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0283 | Val Loss: 0.0090 | Epoch Time: 2.76s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0252 | Val Loss: 0.0091 | Epoch Time: 2.75s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0235 | Val Loss: 0.0049 | Epoch Time: 2.77s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0211 | Val Loss: 0.0056 | Epoch Time: 2.77s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0166 | Val Loss: 0.0091 | Epoch Time: 2.77s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0153 | Val Loss: 0.0039 | Epoch Time: 2.79s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:20:44,871] Trial 47 finished with value: 0.003869536429084947 and parameters: {'learning_rate': 0.0010570247859317348, 'weight_decay': 0.000276818123870866, 'dropout_rate': 0.15814667809688907, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0172 | Val Loss: 0.0113 | Epoch Time: 2.78s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3033 | Val Loss: 0.0148 | Epoch Time: 2.76s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0417 | Val Loss: 0.0209 | Epoch Time: 2.59s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0327 | Val Loss: 0.0083 | Epoch Time: 2.63s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0286 | Val Loss: 0.0076 | Epoch Time: 2.75s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0229 | Val Loss: 0.0066 | Epoch Time: 2.75s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0216 | Val Loss: 0.0082 | Epoch Time: 2.70s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0195 | Val Loss: 0.0269 | Epoch Time: 2.60s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0182 | Val Loss: 0.0032 | Epoch Time: 2.26s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0198 | Val Loss: 0.0053 | Epoch Time: 2.30s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:21:10,483] Trial 48 finished with value: 0.003155026606583961 and parameters: {'learning_rate': 0.002298466378856019, 'weight_decay': 0.0005495743726019015, 'dropout_rate': 0.1600233403209242, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0158 | Val Loss: 0.0196 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.1990 | Val Loss: 0.0163 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0423 | Val Loss: 0.0182 | Epoch Time: 2.25s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0300 | Val Loss: 0.0138 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0263 | Val Loss: 0.0106 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0226 | Val Loss: 0.0091 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0226 | Val Loss: 0.0114 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0220 | Val Loss: 0.0079 | Epoch Time: 2.28s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0197 | Val Loss: 0.0083 | Epoch Time: 2.28s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0234 | Val Loss: 0.0225 | Epoch Time: 2.27s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:21:33,294] Trial 49 finished with value: 0.007869029902697852 and parameters: {'learning_rate': 0.0045057081132032824, 'weight_decay': 0.0005798951508537748, 'dropout_rate': 0.16033144106621497, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0193 | Val Loss: 0.0123 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.1647 | Val Loss: 0.0207 | Epoch Time: 2.41s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0409 | Val Loss: 0.0164 | Epoch Time: 2.30s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0346 | Val Loss: 0.0088 | Epoch Time: 2.36s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0283 | Val Loss: 0.0109 | Epoch Time: 2.37s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0299 | Val Loss: 0.0132 | Epoch Time: 2.35s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0304 | Val Loss: 0.0106 | Epoch Time: 2.34s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0257 | Val Loss: 0.0218 | Epoch Time: 2.39s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0242 | Val Loss: 0.0077 | Epoch Time: 2.37s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0276 | Val Loss: 0.0096 | Epoch Time: 2.36s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:21:56,851] Trial 50 finished with value: 0.007693130453081985 and parameters: {'learning_rate': 0.008597451892936099, 'weight_decay': 0.0002777216893871189, 'dropout_rate': 0.17044421535878185, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0220 | Val Loss: 0.0110 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2892 | Val Loss: 0.0354 | Epoch Time: 2.47s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0474 | Val Loss: 0.0190 | Epoch Time: 2.33s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0370 | Val Loss: 0.0157 | Epoch Time: 2.25s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0344 | Val Loss: 0.0112 | Epoch Time: 2.24s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0292 | Val Loss: 0.0270 | Epoch Time: 2.28s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0269 | Val Loss: 0.0166 | Epoch Time: 2.22s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0240 | Val Loss: 0.0087 | Epoch Time: 2.27s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0198 | Val Loss: 0.0045 | Epoch Time: 2.28s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0191 | Val Loss: 0.0052 | Epoch Time: 2.26s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:22:19,712] Trial 51 finished with value: 0.004491911083522443 and parameters: {'learning_rate': 0.002306651784824165, 'weight_decay': 0.00031955072869415286, 'dropout_rate': 0.14916044027521164, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0163 | Val Loss: 0.0059 | Epoch Time: 2.25s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3957 | Val Loss: 0.0187 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0596 | Val Loss: 0.0189 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0373 | Val Loss: 0.0073 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0331 | Val Loss: 0.0123 | Epoch Time: 2.28s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0316 | Val Loss: 0.0103 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0282 | Val Loss: 0.0127 | Epoch Time: 2.27s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0255 | Val Loss: 0.0045 | Epoch Time: 2.26s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0230 | Val Loss: 0.0066 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0230 | Val Loss: 0.0186 | Epoch Time: 2.27s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:22:42,428] Trial 52 finished with value: 0.004466815725605087 and parameters: {'learning_rate': 0.0014360648618449113, 'weight_decay': 0.00023465557478451288, 'dropout_rate': 0.12475702181577725, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0224 | Val Loss: 0.0106 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3898 | Val Loss: 0.0467 | Epoch Time: 2.32s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0846 | Val Loss: 0.0159 | Epoch Time: 2.25s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0478 | Val Loss: 0.0092 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0333 | Val Loss: 0.0095 | Epoch Time: 2.26s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0310 | Val Loss: 0.0079 | Epoch Time: 2.24s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0286 | Val Loss: 0.0090 | Epoch Time: 2.24s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0253 | Val Loss: 0.0071 | Epoch Time: 2.26s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0223 | Val Loss: 0.0083 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0221 | Val Loss: 0.0065 | Epoch Time: 2.26s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:23:05,072] Trial 53 finished with value: 0.004893668906304576 and parameters: {'learning_rate': 0.0008487330431214487, 'weight_decay': 0.0004159149041898638, 'dropout_rate': 0.14636516212851342, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0217 | Val Loss: 0.0049 | Epoch Time: 2.27s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2562 | Val Loss: 0.0362 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0549 | Val Loss: 0.0163 | Epoch Time: 2.19s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0381 | Val Loss: 0.0108 | Epoch Time: 2.20s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0317 | Val Loss: 0.0079 | Epoch Time: 2.16s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0270 | Val Loss: 0.0110 | Epoch Time: 2.14s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0257 | Val Loss: 0.0117 | Epoch Time: 2.12s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0245 | Val Loss: 0.0078 | Epoch Time: 2.14s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0253 | Val Loss: 0.0106 | Epoch Time: 2.11s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0227 | Val Loss: 0.0070 | Epoch Time: 2.16s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:23:26,747] Trial 54 finished with value: 0.0070064181128018585 and parameters: {'learning_rate': 0.0014477758538193727, 'weight_decay': 0.000515349205862336, 'dropout_rate': 0.1953330558888662, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0210 | Val Loss: 0.0093 | Epoch Time: 2.15s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3442 | Val Loss: 0.0497 | Epoch Time: 2.24s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0644 | Val Loss: 0.0367 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0361 | Val Loss: 0.0067 | Epoch Time: 2.20s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0259 | Val Loss: 0.0098 | Epoch Time: 2.39s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0250 | Val Loss: 0.0107 | Epoch Time: 2.31s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0235 | Val Loss: 0.0050 | Epoch Time: 2.37s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0228 | Val Loss: 0.0083 | Epoch Time: 2.39s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0229 | Val Loss: 0.0123 | Epoch Time: 2.33s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0229 | Val Loss: 0.0203 | Epoch Time: 2.36s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:23:50,021] Trial 55 finished with value: 0.004956013537085582 and parameters: {'learning_rate': 0.0022607087022547584, 'weight_decay': 0.0010210988587767238, 'dropout_rate': 0.11373343722710927, 'embedding_dim': 100}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0218 | Val Loss: 0.0108 | Epoch Time: 2.38s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5813 | Val Loss: 0.0896 | Epoch Time: 2.36s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1374 | Val Loss: 0.0258 | Epoch Time: 2.48s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0697 | Val Loss: 0.0146 | Epoch Time: 2.48s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0523 | Val Loss: 0.0126 | Epoch Time: 2.48s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0427 | Val Loss: 0.0107 | Epoch Time: 2.46s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0318 | Val Loss: 0.0122 | Epoch Time: 2.36s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0274 | Val Loss: 0.0080 | Epoch Time: 2.20s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0271 | Val Loss: 0.0095 | Epoch Time: 2.23s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0235 | Val Loss: 0.0086 | Epoch Time: 2.25s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:24:13,530] Trial 56 finished with value: 0.006281939956640785 and parameters: {'learning_rate': 0.0004733666405687501, 'weight_decay': 0.00017883436658682841, 'dropout_rate': 0.13549690387206387, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0213 | Val Loss: 0.0063 | Epoch Time: 2.19s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3246 | Val Loss: 0.0414 | Epoch Time: 2.24s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0662 | Val Loss: 0.0113 | Epoch Time: 2.20s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0398 | Val Loss: 0.0073 | Epoch Time: 2.20s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0312 | Val Loss: 0.0136 | Epoch Time: 2.16s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0302 | Val Loss: 0.0071 | Epoch Time: 2.18s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0276 | Val Loss: 0.0107 | Epoch Time: 2.16s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0271 | Val Loss: 0.0044 | Epoch Time: 2.22s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0248 | Val Loss: 0.0046 | Epoch Time: 2.18s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0208 | Val Loss: 0.0123 | Epoch Time: 2.19s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:24:35,418] Trial 57 finished with value: 0.004414594856483433 and parameters: {'learning_rate': 0.0012250445910286047, 'weight_decay': 0.0001220429750388209, 'dropout_rate': 0.156432960442002, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0204 | Val Loss: 0.0070 | Epoch Time: 2.14s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 1.2303 | Val Loss: 1.2115 | Epoch Time: 2.19s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 1.1977 | Val Loss: 1.1737 | Epoch Time: 2.18s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 1.1532 | Val Loss: 1.1214 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 1.0888 | Val Loss: 1.0446 | Epoch Time: 2.19s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 1.0127 | Val Loss: 0.9610 | Epoch Time: 2.17s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.9394 | Val Loss: 0.8892 | Epoch Time: 2.17s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.8845 | Val Loss: 0.8381 | Epoch Time: 2.14s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.8450 | Val Loss: 0.8031 | Epoch Time: 2.21s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.8170 | Val Loss: 0.7759 | Epoch Time: 2.23s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:24:57,360] Trial 58 finished with value: 0.7516199452902681 and parameters: {'learning_rate': 1.1344042764804928e-05, 'weight_decay': 0.0007182564455587777, 'dropout_rate': 0.17633920334883524, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.7948 | Val Loss: 0.7516 | Epoch Time: 2.24s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4133 | Val Loss: 0.0520 | Epoch Time: 2.19s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0786 | Val Loss: 0.0172 | Epoch Time: 2.14s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0416 | Val Loss: 0.0112 | Epoch Time: 2.19s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0389 | Val Loss: 0.0101 | Epoch Time: 2.12s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0331 | Val Loss: 0.0096 | Epoch Time: 2.10s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0297 | Val Loss: 0.0128 | Epoch Time: 2.13s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0297 | Val Loss: 0.0112 | Epoch Time: 2.13s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0271 | Val Loss: 0.0090 | Epoch Time: 2.09s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0274 | Val Loss: 0.0130 | Epoch Time: 2.13s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:25:18,680] Trial 59 finished with value: 0.009021904554389547 and parameters: {'learning_rate': 0.0008091776985538995, 'weight_decay': 0.0019394190941324962, 'dropout_rate': 0.2271954286410136, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0282 | Val Loss: 0.0096 | Epoch Time: 2.10s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7293 | Val Loss: 0.4171 | Epoch Time: 2.16s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.3708 | Val Loss: 0.1607 | Epoch Time: 2.13s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1984 | Val Loss: 0.0509 | Epoch Time: 2.14s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.1286 | Val Loss: 0.0273 | Epoch Time: 2.13s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0895 | Val Loss: 0.0181 | Epoch Time: 2.11s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0728 | Val Loss: 0.0137 | Epoch Time: 2.15s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0589 | Val Loss: 0.0127 | Epoch Time: 2.18s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0497 | Val Loss: 0.0111 | Epoch Time: 2.60s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0403 | Val Loss: 0.0093 | Epoch Time: 2.67s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:25:41,575] Trial 60 finished with value: 0.009260928134843256 and parameters: {'learning_rate': 0.00023091072600076807, 'weight_decay': 0.00033798214605361074, 'dropout_rate': 0.4649670461169365, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0370 | Val Loss: 0.0093 | Epoch Time: 2.61s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3350 | Val Loss: 0.0602 | Epoch Time: 2.69s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0685 | Val Loss: 0.0198 | Epoch Time: 2.70s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0420 | Val Loss: 0.0124 | Epoch Time: 2.71s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0310 | Val Loss: 0.0118 | Epoch Time: 2.70s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0268 | Val Loss: 0.0098 | Epoch Time: 2.66s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0223 | Val Loss: 0.0076 | Epoch Time: 2.67s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0234 | Val Loss: 0.0075 | Epoch Time: 2.63s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0200 | Val Loss: 0.0267 | Epoch Time: 2.63s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0199 | Val Loss: 0.0080 | Epoch Time: 2.66s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:26:08,300] Trial 61 finished with value: 0.0074826990421631495 and parameters: {'learning_rate': 0.0011399036884845852, 'weight_decay': 0.00012123910035572741, 'dropout_rate': 0.15641243632001942, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0192 | Val Loss: 0.0080 | Epoch Time: 2.68s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2853 | Val Loss: 0.0168 | Epoch Time: 2.73s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0561 | Val Loss: 0.0150 | Epoch Time: 2.77s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0366 | Val Loss: 0.0223 | Epoch Time: 2.71s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0284 | Val Loss: 0.0099 | Epoch Time: 2.77s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0247 | Val Loss: 0.0072 | Epoch Time: 2.76s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0213 | Val Loss: 0.0080 | Epoch Time: 2.83s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0214 | Val Loss: 0.0107 | Epoch Time: 2.79s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0171 | Val Loss: 0.0099 | Epoch Time: 2.75s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0166 | Val Loss: 0.0095 | Epoch Time: 2.75s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:26:35,954] Trial 62 finished with value: 0.004853014310566489 and parameters: {'learning_rate': 0.0015365106902253361, 'weight_decay': 5.6581499890070106e-05, 'dropout_rate': 0.13987713723754097, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0168 | Val Loss: 0.0049 | Epoch Time: 2.78s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2514 | Val Loss: 0.0220 | Epoch Time: 2.67s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0492 | Val Loss: 0.0190 | Epoch Time: 2.65s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0396 | Val Loss: 0.0191 | Epoch Time: 2.74s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0289 | Val Loss: 0.0097 | Epoch Time: 2.72s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0246 | Val Loss: 0.0057 | Epoch Time: 2.77s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0254 | Val Loss: 0.0079 | Epoch Time: 2.74s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0187 | Val Loss: 0.0108 | Epoch Time: 2.78s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0173 | Val Loss: 0.0110 | Epoch Time: 2.77s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0174 | Val Loss: 0.0062 | Epoch Time: 2.76s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:27:03,289] Trial 63 finished with value: 0.005006977543719889 and parameters: {'learning_rate': 0.002193326833208389, 'weight_decay': 0.00025224144362361343, 'dropout_rate': 0.1925711034408158, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0161 | Val Loss: 0.0050 | Epoch Time: 2.72s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3692 | Val Loss: 0.0467 | Epoch Time: 2.23s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0809 | Val Loss: 0.0190 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0382 | Val Loss: 0.0137 | Epoch Time: 2.25s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0295 | Val Loss: 0.0126 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0209 | Val Loss: 0.0148 | Epoch Time: 2.26s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0215 | Val Loss: 0.0086 | Epoch Time: 2.26s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0155 | Val Loss: 0.0056 | Epoch Time: 2.25s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0160 | Val Loss: 0.0095 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0142 | Val Loss: 0.0058 | Epoch Time: 2.25s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:27:25,859] Trial 64 finished with value: 0.00557595998533768 and parameters: {'learning_rate': 0.003083155622786384, 'weight_decay': 0.00013606917122697184, 'dropout_rate': 0.15933471146753017, 'embedding_dim': 100}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0089 | Val Loss: 0.0060 | Epoch Time: 2.22s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3807 | Val Loss: 0.0338 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0640 | Val Loss: 0.0144 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0374 | Val Loss: 0.0083 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0286 | Val Loss: 0.0137 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0244 | Val Loss: 0.0079 | Epoch Time: 2.41s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0235 | Val Loss: 0.0072 | Epoch Time: 2.39s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0191 | Val Loss: 0.0050 | Epoch Time: 2.32s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0194 | Val Loss: 0.0064 | Epoch Time: 2.35s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0167 | Val Loss: 0.0069 | Epoch Time: 2.34s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:27:49,143] Trial 65 finished with value: 0.004966724905565942 and parameters: {'learning_rate': 0.001021929053107482, 'weight_decay': 7.053230184491367e-05, 'dropout_rate': 0.11093987643444858, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0160 | Val Loss: 0.0058 | Epoch Time: 2.34s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4581 | Val Loss: 0.0715 | Epoch Time: 2.31s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1153 | Val Loss: 0.0170 | Epoch Time: 2.29s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0607 | Val Loss: 0.0098 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0431 | Val Loss: 0.0070 | Epoch Time: 2.35s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0373 | Val Loss: 0.0075 | Epoch Time: 2.30s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0276 | Val Loss: 0.0047 | Epoch Time: 2.31s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0281 | Val Loss: 0.0067 | Epoch Time: 2.24s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0238 | Val Loss: 0.0045 | Epoch Time: 2.22s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0235 | Val Loss: 0.0094 | Epoch Time: 2.24s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:28:11,962] Trial 66 finished with value: 0.004476249241379656 and parameters: {'learning_rate': 0.0007249858567013775, 'weight_decay': 4.332179034227425e-05, 'dropout_rate': 0.33864819424498427, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0221 | Val Loss: 0.0055 | Epoch Time: 2.24s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5237 | Val Loss: 0.1294 | Epoch Time: 2.26s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1720 | Val Loss: 0.0544 | Epoch Time: 2.30s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0977 | Val Loss: 0.0405 | Epoch Time: 2.25s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0710 | Val Loss: 0.0302 | Epoch Time: 2.27s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0519 | Val Loss: 0.0236 | Epoch Time: 2.24s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0406 | Val Loss: 0.0162 | Epoch Time: 2.27s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0303 | Val Loss: 0.0090 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0222 | Val Loss: 0.0051 | Epoch Time: 2.28s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0195 | Val Loss: 0.0040 | Epoch Time: 2.29s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:28:34,710] Trial 67 finished with value: 0.0035983412702872528 and parameters: {'learning_rate': 0.0005680181681790361, 'weight_decay': 0.00018637965598649234, 'dropout_rate': 0.20628337028894989, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0198 | Val Loss: 0.0036 | Epoch Time: 2.28s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5086 | Val Loss: 0.0883 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1412 | Val Loss: 0.0240 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0799 | Val Loss: 0.0185 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0532 | Val Loss: 0.0118 | Epoch Time: 2.30s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0416 | Val Loss: 0.0102 | Epoch Time: 2.28s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0352 | Val Loss: 0.0080 | Epoch Time: 2.28s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0334 | Val Loss: 0.0066 | Epoch Time: 2.28s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0289 | Val Loss: 0.0077 | Epoch Time: 2.29s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0240 | Val Loss: 0.0071 | Epoch Time: 2.29s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:28:57,516] Trial 68 finished with value: 0.005582795083360144 and parameters: {'learning_rate': 0.0005767758499375582, 'weight_decay': 0.00017578638328095674, 'dropout_rate': 0.18499870449020533, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0241 | Val Loss: 0.0056 | Epoch Time: 2.27s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.6725 | Val Loss: 0.1849 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.2156 | Val Loss: 0.0499 | Epoch Time: 2.25s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1106 | Val Loss: 0.0206 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0719 | Val Loss: 0.0164 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0531 | Val Loss: 0.0132 | Epoch Time: 2.29s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0430 | Val Loss: 0.0089 | Epoch Time: 2.32s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0363 | Val Loss: 0.0088 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0307 | Val Loss: 0.0103 | Epoch Time: 2.30s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0281 | Val Loss: 0.0067 | Epoch Time: 2.28s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:29:20,423] Trial 69 finished with value: 0.006660093287283289 and parameters: {'learning_rate': 0.0003859243280337003, 'weight_decay': 8.72537790723361e-05, 'dropout_rate': 0.20854299075762722, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0250 | Val Loss: 0.0073 | Epoch Time: 2.28s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7517 | Val Loss: 0.3898 | Epoch Time: 2.27s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.3300 | Val Loss: 0.1189 | Epoch Time: 2.29s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1854 | Val Loss: 0.0616 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.1211 | Val Loss: 0.0300 | Epoch Time: 2.22s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0857 | Val Loss: 0.0212 | Epoch Time: 2.25s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0606 | Val Loss: 0.0138 | Epoch Time: 2.29s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0483 | Val Loss: 0.0119 | Epoch Time: 2.42s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0408 | Val Loss: 0.0108 | Epoch Time: 2.36s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0366 | Val Loss: 0.0079 | Epoch Time: 2.31s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:29:43,544] Trial 70 finished with value: 0.007873407511700256 and parameters: {'learning_rate': 0.0002564753109730615, 'weight_decay': 0.00048013320313109023, 'dropout_rate': 0.23625733528387594, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0334 | Val Loss: 0.0087 | Epoch Time: 2.41s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3292 | Val Loss: 0.0277 | Epoch Time: 2.39s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0622 | Val Loss: 0.0093 | Epoch Time: 2.34s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0367 | Val Loss: 0.0142 | Epoch Time: 2.33s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0292 | Val Loss: 0.0092 | Epoch Time: 2.36s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0275 | Val Loss: 0.0050 | Epoch Time: 2.40s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0237 | Val Loss: 0.0069 | Epoch Time: 2.36s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0224 | Val Loss: 0.0048 | Epoch Time: 2.40s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0184 | Val Loss: 0.0140 | Epoch Time: 2.33s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0199 | Val Loss: 0.0054 | Epoch Time: 2.26s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:30:07,009] Trial 71 finished with value: 0.00413296022894448 and parameters: {'learning_rate': 0.0012432863548903995, 'weight_decay': 0.00011966194922192164, 'dropout_rate': 0.170039151292051, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0150 | Val Loss: 0.0041 | Epoch Time: 2.28s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2785 | Val Loss: 0.0209 | Epoch Time: 2.25s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0493 | Val Loss: 0.0143 | Epoch Time: 2.23s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0296 | Val Loss: 0.0080 | Epoch Time: 2.24s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0247 | Val Loss: 0.0160 | Epoch Time: 2.26s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0224 | Val Loss: 0.0082 | Epoch Time: 2.29s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0229 | Val Loss: 0.0112 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0197 | Val Loss: 0.0111 | Epoch Time: 2.22s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0163 | Val Loss: 0.0060 | Epoch Time: 2.24s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0158 | Val Loss: 0.0091 | Epoch Time: 2.23s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:30:29,560] Trial 72 finished with value: 0.003933875764125078 and parameters: {'learning_rate': 0.0017352711576234066, 'weight_decay': 0.0002050548868543643, 'dropout_rate': 0.17495983392691378, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0142 | Val Loss: 0.0039 | Epoch Time: 2.28s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3128 | Val Loss: 0.0313 | Epoch Time: 2.33s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0586 | Val Loss: 0.0137 | Epoch Time: 2.25s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0373 | Val Loss: 0.0151 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0311 | Val Loss: 0.0118 | Epoch Time: 2.25s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0270 | Val Loss: 0.0086 | Epoch Time: 2.26s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0246 | Val Loss: 0.0070 | Epoch Time: 2.25s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0220 | Val Loss: 0.0110 | Epoch Time: 2.25s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0195 | Val Loss: 0.0099 | Epoch Time: 2.25s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0193 | Val Loss: 0.0130 | Epoch Time: 2.28s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:30:52,209] Trial 73 finished with value: 0.007037785179407717 and parameters: {'learning_rate': 0.0016981200441075278, 'weight_decay': 0.0002080821408876851, 'dropout_rate': 0.1731651058054892, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0163 | Val Loss: 0.0094 | Epoch Time: 2.27s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.1920 | Val Loss: 0.0175 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0610 | Val Loss: 0.0331 | Epoch Time: 2.28s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0411 | Val Loss: 0.0165 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0298 | Val Loss: 0.0113 | Epoch Time: 2.26s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0237 | Val Loss: 0.0147 | Epoch Time: 2.25s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0231 | Val Loss: 0.0103 | Epoch Time: 2.26s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0197 | Val Loss: 0.0047 | Epoch Time: 2.29s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0179 | Val Loss: 0.0065 | Epoch Time: 2.29s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0195 | Val Loss: 0.0053 | Epoch Time: 2.27s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:31:15,020] Trial 74 finished with value: 0.004747424667858536 and parameters: {'learning_rate': 0.004144516315677589, 'weight_decay': 0.00025187833743249024, 'dropout_rate': 0.18907466484857205, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0177 | Val Loss: 0.0090 | Epoch Time: 2.32s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5610 | Val Loss: 0.1017 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1513 | Val Loss: 0.0343 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0744 | Val Loss: 0.0172 | Epoch Time: 2.27s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0510 | Val Loss: 0.0111 | Epoch Time: 2.31s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0402 | Val Loss: 0.0076 | Epoch Time: 2.29s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0325 | Val Loss: 0.0084 | Epoch Time: 2.30s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0291 | Val Loss: 0.0069 | Epoch Time: 2.28s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0248 | Val Loss: 0.0076 | Epoch Time: 2.28s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0214 | Val Loss: 0.0064 | Epoch Time: 2.70s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:31:38,786] Trial 75 finished with value: 0.005341926325874288 and parameters: {'learning_rate': 0.00047366530894567195, 'weight_decay': 0.0003640354100127264, 'dropout_rate': 0.2952884296019186, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0212 | Val Loss: 0.0053 | Epoch Time: 2.78s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4159 | Val Loss: 0.0385 | Epoch Time: 2.75s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0542 | Val Loss: 0.0267 | Epoch Time: 2.66s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0332 | Val Loss: 0.0082 | Epoch Time: 2.66s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0233 | Val Loss: 0.0099 | Epoch Time: 2.75s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0217 | Val Loss: 0.0093 | Epoch Time: 2.75s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0232 | Val Loss: 0.0108 | Epoch Time: 2.75s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0197 | Val Loss: 0.0085 | Epoch Time: 2.73s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0192 | Val Loss: 0.0167 | Epoch Time: 2.74s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0204 | Val Loss: 0.0176 | Epoch Time: 2.76s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:32:06,056] Trial 76 finished with value: 0.004257634460734925 and parameters: {'learning_rate': 0.0026670039739665565, 'weight_decay': 0.0006209379649195966, 'dropout_rate': 0.12414046951538078, 'embedding_dim': 100}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0205 | Val Loss: 0.0043 | Epoch Time: 2.70s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2992 | Val Loss: 0.0237 | Epoch Time: 2.75s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0461 | Val Loss: 0.0123 | Epoch Time: 2.79s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0320 | Val Loss: 0.0179 | Epoch Time: 2.77s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0279 | Val Loss: 0.0107 | Epoch Time: 2.77s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0263 | Val Loss: 0.0220 | Epoch Time: 2.75s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0235 | Val Loss: 0.0086 | Epoch Time: 2.78s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0213 | Val Loss: 0.0087 | Epoch Time: 2.75s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0201 | Val Loss: 0.0080 | Epoch Time: 2.75s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0201 | Val Loss: 0.0089 | Epoch Time: 2.72s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:32:33,644] Trial 77 finished with value: 0.006796254576798792 and parameters: {'learning_rate': 0.001959219307633429, 'weight_decay': 0.00030141602122992693, 'dropout_rate': 0.22205024675603235, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0177 | Val Loss: 0.0068 | Epoch Time: 2.74s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5618 | Val Loss: 0.0771 | Epoch Time: 2.74s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1377 | Val Loss: 0.0212 | Epoch Time: 2.69s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0656 | Val Loss: 0.0128 | Epoch Time: 2.75s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0438 | Val Loss: 0.0111 | Epoch Time: 2.78s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0308 | Val Loss: 0.0123 | Epoch Time: 2.75s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0284 | Val Loss: 0.0058 | Epoch Time: 2.77s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0225 | Val Loss: 0.0082 | Epoch Time: 2.74s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0244 | Val Loss: 0.0058 | Epoch Time: 2.72s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0193 | Val Loss: 0.0119 | Epoch Time: 2.75s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:33:01,090] Trial 78 finished with value: 0.005776232210454538 and parameters: {'learning_rate': 0.0007129883400281339, 'weight_decay': 0.00014624929864003562, 'dropout_rate': 0.24347899164132458, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0192 | Val Loss: 0.0067 | Epoch Time: 2.74s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3315 | Val Loss: 0.0345 | Epoch Time: 2.65s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0741 | Val Loss: 0.0155 | Epoch Time: 2.30s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0431 | Val Loss: 0.0094 | Epoch Time: 2.28s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0359 | Val Loss: 0.0112 | Epoch Time: 2.27s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0278 | Val Loss: 0.0121 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0270 | Val Loss: 0.0095 | Epoch Time: 2.28s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0236 | Val Loss: 0.0056 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0210 | Val Loss: 0.0059 | Epoch Time: 2.25s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0193 | Val Loss: 0.0090 | Epoch Time: 2.25s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:33:24,243] Trial 79 finished with value: 0.005559616604831942 and parameters: {'learning_rate': 0.000951842968990295, 'weight_decay': 0.0001970244147837008, 'dropout_rate': 0.20480691133837545, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0219 | Val Loss: 0.0214 | Epoch Time: 2.28s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.5800 | Val Loss: 0.1110 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1551 | Val Loss: 0.0282 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0846 | Val Loss: 0.0149 | Epoch Time: 2.27s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0533 | Val Loss: 0.0090 | Epoch Time: 2.28s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0416 | Val Loss: 0.0072 | Epoch Time: 2.33s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0345 | Val Loss: 0.0061 | Epoch Time: 2.36s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0267 | Val Loss: 0.0055 | Epoch Time: 2.36s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0269 | Val Loss: 0.0047 | Epoch Time: 2.35s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0247 | Val Loss: 0.0101 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:33:47,378] Trial 80 finished with value: 0.004617593017822215 and parameters: {'learning_rate': 0.0005595024979614636, 'weight_decay': 0.00010854438170146566, 'dropout_rate': 0.1657288300522047, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0221 | Val Loss: 0.0046 | Epoch Time: 2.31s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3493 | Val Loss: 0.0330 | Epoch Time: 2.35s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0762 | Val Loss: 0.0130 | Epoch Time: 2.33s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0449 | Val Loss: 0.0083 | Epoch Time: 2.33s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0316 | Val Loss: 0.0063 | Epoch Time: 2.33s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0293 | Val Loss: 0.0076 | Epoch Time: 2.45s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0269 | Val Loss: 0.0067 | Epoch Time: 2.54s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0244 | Val Loss: 0.0101 | Epoch Time: 2.37s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0238 | Val Loss: 0.0065 | Epoch Time: 2.21s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0197 | Val Loss: 0.0067 | Epoch Time: 2.22s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:34:10,759] Trial 81 finished with value: 0.005319932557286329 and parameters: {'learning_rate': 0.001313519814701793, 'weight_decay': 6.688561173925672e-05, 'dropout_rate': 0.15063687901757528, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0206 | Val Loss: 0.0053 | Epoch Time: 2.25s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2993 | Val Loss: 0.0254 | Epoch Time: 2.22s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0589 | Val Loss: 0.0182 | Epoch Time: 2.22s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0369 | Val Loss: 0.0090 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0331 | Val Loss: 0.0133 | Epoch Time: 2.24s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0295 | Val Loss: 0.0084 | Epoch Time: 2.26s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0251 | Val Loss: 0.0081 | Epoch Time: 2.24s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0209 | Val Loss: 0.0068 | Epoch Time: 2.23s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0244 | Val Loss: 0.0091 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0193 | Val Loss: 0.0066 | Epoch Time: 2.25s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:34:33,219] Trial 82 finished with value: 0.006585131620467823 and parameters: {'learning_rate': 0.0015957109430987176, 'weight_decay': 0.00016987623794523316, 'dropout_rate': 0.1773290584654284, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0139 | Val Loss: 0.0095 | Epoch Time: 2.26s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4358 | Val Loss: 0.0440 | Epoch Time: 2.23s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0876 | Val Loss: 0.0121 | Epoch Time: 2.17s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0451 | Val Loss: 0.0055 | Epoch Time: 2.20s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0368 | Val Loss: 0.0070 | Epoch Time: 2.22s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0310 | Val Loss: 0.0045 | Epoch Time: 2.21s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0301 | Val Loss: 0.0072 | Epoch Time: 2.19s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0285 | Val Loss: 0.0088 | Epoch Time: 2.20s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0233 | Val Loss: 0.0059 | Epoch Time: 2.23s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0232 | Val Loss: 0.0045 | Epoch Time: 2.22s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:34:55,311] Trial 83 finished with value: 0.004523746129512235 and parameters: {'learning_rate': 0.0010369925745453109, 'weight_decay': 8.929721826480668e-05, 'dropout_rate': 0.14542034610541751, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0238 | Val Loss: 0.0061 | Epoch Time: 2.20s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4592 | Val Loss: 0.0468 | Epoch Time: 2.24s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0946 | Val Loss: 0.0129 | Epoch Time: 2.20s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0548 | Val Loss: 0.0169 | Epoch Time: 2.17s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0385 | Val Loss: 0.0090 | Epoch Time: 2.20s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0331 | Val Loss: 0.0077 | Epoch Time: 2.12s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0302 | Val Loss: 0.0113 | Epoch Time: 2.15s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0252 | Val Loss: 0.0097 | Epoch Time: 2.12s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0230 | Val Loss: 0.0077 | Epoch Time: 2.13s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0229 | Val Loss: 0.0050 | Epoch Time: 2.15s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:35:16,955] Trial 84 finished with value: 0.0032062358727818073 and parameters: {'learning_rate': 0.0007738631788193628, 'weight_decay': 0.00042690642572204795, 'dropout_rate': 0.13147074392593208, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0202 | Val Loss: 0.0032 | Epoch Time: 2.13s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.8098 | Val Loss: 0.3486 | Epoch Time: 2.21s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.3144 | Val Loss: 0.0886 | Epoch Time: 2.23s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.1679 | Val Loss: 0.0414 | Epoch Time: 2.21s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.1030 | Val Loss: 0.0194 | Epoch Time: 2.18s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0693 | Val Loss: 0.0144 | Epoch Time: 2.26s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0533 | Val Loss: 0.0113 | Epoch Time: 2.26s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0418 | Val Loss: 0.0121 | Epoch Time: 2.24s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0354 | Val Loss: 0.0069 | Epoch Time: 2.36s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0283 | Val Loss: 0.0064 | Epoch Time: 2.45s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:35:39,688] Trial 85 finished with value: 0.005854980047070546 and parameters: {'learning_rate': 0.0003388779495510317, 'weight_decay': 0.00044588165047879894, 'dropout_rate': 0.12577272331706346, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0271 | Val Loss: 0.0059 | Epoch Time: 2.32s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4030 | Val Loss: 0.0519 | Epoch Time: 2.39s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0932 | Val Loss: 0.0148 | Epoch Time: 2.46s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0548 | Val Loss: 0.0115 | Epoch Time: 2.50s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0380 | Val Loss: 0.0111 | Epoch Time: 2.57s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0330 | Val Loss: 0.0103 | Epoch Time: 2.50s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0287 | Val Loss: 0.0101 | Epoch Time: 2.56s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0268 | Val Loss: 0.0132 | Epoch Time: 2.55s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0229 | Val Loss: 0.0049 | Epoch Time: 2.57s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0241 | Val Loss: 0.0056 | Epoch Time: 2.50s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:36:04,726] Trial 86 finished with value: 0.004880377654327247 and parameters: {'learning_rate': 0.0007697256946626167, 'weight_decay': 0.0003713004107662705, 'dropout_rate': 0.19883873918963182, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0214 | Val Loss: 0.0070 | Epoch Time: 2.42s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2473 | Val Loss: 0.0274 | Epoch Time: 2.20s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0553 | Val Loss: 0.0215 | Epoch Time: 2.18s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0483 | Val Loss: 0.0204 | Epoch Time: 2.18s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0478 | Val Loss: 0.0190 | Epoch Time: 2.20s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0461 | Val Loss: 0.0316 | Epoch Time: 2.20s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0451 | Val Loss: 0.0248 | Epoch Time: 2.17s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0450 | Val Loss: 0.0233 | Epoch Time: 2.26s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0436 | Val Loss: 0.0242 | Epoch Time: 2.19s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0477 | Val Loss: 0.0152 | Epoch Time: 2.19s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:36:26,677] Trial 87 finished with value: 0.01283756857274741 and parameters: {'learning_rate': 0.002258684935182952, 'weight_decay': 0.00435151617106033, 'dropout_rate': 0.1341774522424487, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0459 | Val Loss: 0.0128 | Epoch Time: 2.15s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.4304 | Val Loss: 0.0679 | Epoch Time: 2.21s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.1187 | Val Loss: 0.0213 | Epoch Time: 2.17s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0645 | Val Loss: 0.0132 | Epoch Time: 2.17s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0451 | Val Loss: 0.0130 | Epoch Time: 2.19s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0353 | Val Loss: 0.0085 | Epoch Time: 2.17s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0299 | Val Loss: 0.0076 | Epoch Time: 2.15s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0268 | Val Loss: 0.0065 | Epoch Time: 2.16s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0241 | Val Loss: 0.0069 | Epoch Time: 2.14s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0240 | Val Loss: 0.0092 | Epoch Time: 2.20s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:36:48,398] Trial 88 finished with value: 0.006488265417252106 and parameters: {'learning_rate': 0.0006414115348710157, 'weight_decay': 0.00026261437894226677, 'dropout_rate': 0.10202371987193315, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0211 | Val Loss: 0.0135 | Epoch Time: 2.14s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.7063 | Val Loss: 0.2586 | Epoch Time: 2.18s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.2018 | Val Loss: 0.0468 | Epoch Time: 2.23s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0890 | Val Loss: 0.0312 | Epoch Time: 2.24s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0624 | Val Loss: 0.0135 | Epoch Time: 2.20s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0500 | Val Loss: 0.0859 | Epoch Time: 2.21s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0486 | Val Loss: 0.0162 | Epoch Time: 2.21s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0404 | Val Loss: 0.0123 | Epoch Time: 2.21s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0441 | Val Loss: 0.0156 | Epoch Time: 2.13s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0352 | Val Loss: 0.0063 | Epoch Time: 2.14s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:37:10,307] Trial 89 finished with value: 0.005723778264357968 and parameters: {'learning_rate': 0.00042912106174325463, 'weight_decay': 0.0002299253861364034, 'dropout_rate': 0.16865696825035925, 'embedding_dim': 100}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0357 | Val Loss: 0.0057 | Epoch Time: 2.14s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.1701 | Val Loss: 0.0260 | Epoch Time: 2.20s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0364 | Val Loss: 0.0110 | Epoch Time: 2.19s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0284 | Val Loss: 0.0090 | Epoch Time: 2.18s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0235 | Val Loss: 0.0400 | Epoch Time: 2.17s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0239 | Val Loss: 0.0072 | Epoch Time: 2.20s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0206 | Val Loss: 0.0354 | Epoch Time: 2.23s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0244 | Val Loss: 0.0215 | Epoch Time: 2.18s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0228 | Val Loss: 0.0138 | Epoch Time: 2.26s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0179 | Val Loss: 0.0117 | Epoch Time: 2.21s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:37:32,392] Trial 90 finished with value: 0.004443831480931558 and parameters: {'learning_rate': 0.003372502798691975, 'weight_decay': 0.0006786142715551611, 'dropout_rate': 0.1554892655876351, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0199 | Val Loss: 0.0044 | Epoch Time: 2.24s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3232 | Val Loss: 0.0238 | Epoch Time: 2.51s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0600 | Val Loss: 0.0093 | Epoch Time: 2.71s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0366 | Val Loss: 0.0132 | Epoch Time: 2.44s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0313 | Val Loss: 0.0102 | Epoch Time: 2.42s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0261 | Val Loss: 0.0093 | Epoch Time: 2.71s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0246 | Val Loss: 0.0069 | Epoch Time: 2.73s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0238 | Val Loss: 0.0141 | Epoch Time: 2.74s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0215 | Val Loss: 0.0060 | Epoch Time: 2.74s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0181 | Val Loss: 0.0032 | Epoch Time: 2.73s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:37:58,898] Trial 91 finished with value: 0.003236830371486916 and parameters: {'learning_rate': 0.0013047404462690774, 'weight_decay': 0.00012864561593193936, 'dropout_rate': 0.1391711433691832, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0186 | Val Loss: 0.0183 | Epoch Time: 2.76s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3804 | Val Loss: 0.0461 | Epoch Time: 2.72s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0909 | Val Loss: 0.0147 | Epoch Time: 2.72s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0509 | Val Loss: 0.0120 | Epoch Time: 2.72s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0375 | Val Loss: 0.0094 | Epoch Time: 2.74s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0327 | Val Loss: 0.0077 | Epoch Time: 2.78s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0294 | Val Loss: 0.0077 | Epoch Time: 2.85s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0253 | Val Loss: 0.0150 | Epoch Time: 2.83s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0214 | Val Loss: 0.0155 | Epoch Time: 2.71s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0237 | Val Loss: 0.0053 | Epoch Time: 2.75s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:38:26,536] Trial 92 finished with value: 0.005314266755444854 and parameters: {'learning_rate': 0.0009032995029307297, 'weight_decay': 0.00013325479732832432, 'dropout_rate': 0.1861660923448427, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0207 | Val Loss: 0.0083 | Epoch Time: 2.81s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2942 | Val Loss: 0.0373 | Epoch Time: 2.80s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0551 | Val Loss: 0.0089 | Epoch Time: 2.76s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0379 | Val Loss: 0.0106 | Epoch Time: 2.78s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0330 | Val Loss: 0.0122 | Epoch Time: 2.76s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0304 | Val Loss: 0.0149 | Epoch Time: 2.68s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0265 | Val Loss: 0.0069 | Epoch Time: 2.66s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0251 | Val Loss: 0.0075 | Epoch Time: 2.69s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0250 | Val Loss: 0.0079 | Epoch Time: 2.77s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0237 | Val Loss: 0.0066 | Epoch Time: 2.77s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:38:53,914] Trial 93 finished with value: 0.00659162671734286 and parameters: {'learning_rate': 0.0013233492047914441, 'weight_decay': 0.0008704344122404112, 'dropout_rate': 0.11612278277080625, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0245 | Val Loss: 0.0081 | Epoch Time: 2.68s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2763 | Val Loss: 0.0189 | Epoch Time: 2.68s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0528 | Val Loss: 0.0159 | Epoch Time: 2.72s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0326 | Val Loss: 0.0089 | Epoch Time: 2.79s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0289 | Val Loss: 0.0068 | Epoch Time: 2.49s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0237 | Val Loss: 0.0086 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0218 | Val Loss: 0.0061 | Epoch Time: 2.29s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0215 | Val Loss: 0.0150 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0208 | Val Loss: 0.0067 | Epoch Time: 2.27s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0182 | Val Loss: 0.0100 | Epoch Time: 2.26s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:39:18,291] Trial 94 finished with value: 0.006102275792805832 and parameters: {'learning_rate': 0.0020562271892792137, 'weight_decay': 0.00019556511219666662, 'dropout_rate': 0.1400245893007027, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0180 | Val Loss: 0.0207 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3289 | Val Loss: 0.0199 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0548 | Val Loss: 0.0097 | Epoch Time: 2.26s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0361 | Val Loss: 0.0170 | Epoch Time: 2.26s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0282 | Val Loss: 0.0075 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0273 | Val Loss: 0.0076 | Epoch Time: 2.25s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0248 | Val Loss: 0.0085 | Epoch Time: 2.27s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0246 | Val Loss: 0.0061 | Epoch Time: 2.31s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0224 | Val Loss: 0.0077 | Epoch Time: 2.36s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0209 | Val Loss: 0.0098 | Epoch Time: 2.30s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:39:41,233] Trial 95 finished with value: 0.006146660999146789 and parameters: {'learning_rate': 0.001845449117875213, 'weight_decay': 0.00030888263592066526, 'dropout_rate': 0.17969573112128961, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0217 | Val Loss: 0.0084 | Epoch Time: 2.34s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3472 | Val Loss: 0.0312 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0642 | Val Loss: 0.0108 | Epoch Time: 2.38s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0420 | Val Loss: 0.0124 | Epoch Time: 2.35s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0368 | Val Loss: 0.0089 | Epoch Time: 2.40s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0300 | Val Loss: 0.0078 | Epoch Time: 2.35s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0284 | Val Loss: 0.0105 | Epoch Time: 2.37s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0249 | Val Loss: 0.0123 | Epoch Time: 2.39s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0235 | Val Loss: 0.0049 | Epoch Time: 2.32s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0218 | Val Loss: 0.0163 | Epoch Time: 2.28s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:40:04,670] Trial 96 finished with value: 0.004862780463837978 and parameters: {'learning_rate': 0.0011438636216100303, 'weight_decay': 0.0011751088221611864, 'dropout_rate': 0.16688963203653165, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0212 | Val Loss: 0.0080 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2429 | Val Loss: 0.0280 | Epoch Time: 2.29s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0490 | Val Loss: 0.0139 | Epoch Time: 2.54s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0358 | Val Loss: 0.0146 | Epoch Time: 2.27s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0298 | Val Loss: 0.0224 | Epoch Time: 2.42s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0244 | Val Loss: 0.0132 | Epoch Time: 2.47s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0221 | Val Loss: 0.0273 | Epoch Time: 2.50s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0219 | Val Loss: 0.0069 | Epoch Time: 2.26s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0187 | Val Loss: 0.0147 | Epoch Time: 2.30s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0168 | Val Loss: 0.0067 | Epoch Time: 2.30s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:40:28,329] Trial 97 finished with value: 0.005035208049922667 and parameters: {'learning_rate': 0.0025912573944062317, 'weight_decay': 0.00010767841987514245, 'dropout_rate': 0.13061888632802135, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0173 | Val Loss: 0.0050 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.2910 | Val Loss: 0.0183 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0536 | Val Loss: 0.0231 | Epoch Time: 2.31s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0385 | Val Loss: 0.0163 | Epoch Time: 2.28s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0285 | Val Loss: 0.0101 | Epoch Time: 2.28s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0275 | Val Loss: 0.0156 | Epoch Time: 2.27s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0234 | Val Loss: 0.0069 | Epoch Time: 2.29s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0197 | Val Loss: 0.0062 | Epoch Time: 2.48s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0169 | Val Loss: 0.0051 | Epoch Time: 2.34s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0183 | Val Loss: 0.0053 | Epoch Time: 2.29s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:40:51,461] Trial 98 finished with value: 0.0036113627896410955 and parameters: {'learning_rate': 0.001524183592585175, 'weight_decay': 0.00015047517094576, 'dropout_rate': 0.109522411536887, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0164 | Val Loss: 0.0036 | Epoch Time: 2.29s\n",
      "Training Complete !!!\n",
      "Using device: cuda\n",
      "Epoch: 1/10\n",
      "Epoch [1/10] | Train Loss: 0.3178 | Val Loss: 0.0230 | Epoch Time: 2.28s\n",
      "Epoch: 2/10\n",
      "Epoch [2/10] | Train Loss: 0.0584 | Val Loss: 0.0131 | Epoch Time: 2.27s\n",
      "Epoch: 3/10\n",
      "Epoch [3/10] | Train Loss: 0.0367 | Val Loss: 0.0143 | Epoch Time: 2.29s\n",
      "Epoch: 4/10\n",
      "Epoch [4/10] | Train Loss: 0.0289 | Val Loss: 0.0172 | Epoch Time: 2.29s\n",
      "Epoch: 5/10\n",
      "Epoch [5/10] | Train Loss: 0.0273 | Val Loss: 0.0192 | Epoch Time: 2.32s\n",
      "Epoch: 6/10\n",
      "Epoch [6/10] | Train Loss: 0.0259 | Val Loss: 0.0063 | Epoch Time: 2.34s\n",
      "Epoch: 7/10\n",
      "Epoch [7/10] | Train Loss: 0.0232 | Val Loss: 0.0157 | Epoch Time: 2.30s\n",
      "Epoch: 8/10\n",
      "Epoch [8/10] | Train Loss: 0.0197 | Val Loss: 0.0078 | Epoch Time: 2.31s\n",
      "Epoch: 9/10\n",
      "Epoch [9/10] | Train Loss: 0.0208 | Val Loss: 0.0096 | Epoch Time: 2.32s\n",
      "Epoch: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-27 02:41:14,403] Trial 99 finished with value: 0.006292871489021827 and parameters: {'learning_rate': 0.0014734561066555448, 'weight_decay': 0.0001572081843926454, 'dropout_rate': 0.10878636703013755, 'embedding_dim': 10}. Best is trial 32 with value: 0.003094467500759688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] | Train Loss: 0.0198 | Val Loss: 0.0096 | Epoch Time: 2.22s\n",
      "Training Complete !!!\n",
      "{'learning_rate': 0.00047307239371176485, 'weight_decay': 0.0002572176180532664, 'dropout_rate': 0.1475648189305909, 'embedding_dim': 10}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.1, 0.5)\n",
    "    embedding_dim = trial.suggest_categorical('embedding_dim', [10, 50, 100])\n",
    "    \n",
    "    # Define your model, optimizer, and loss function here\n",
    "    model = RecommendationModel(num_categories, num_subcategories, embedding_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    \n",
    "    # Train your model and evaluate performance on validation data\n",
    "    best_val_loss = train_and_evaluate(model, optimizer, criterion, train_loader, val_loader, num_epochs=10)\n",
    "\n",
    "    \n",
    "    return best_val_loss  # or return -val_accuracy for maximization\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the separated training data into df\n",
    "\n",
    "test_df = pd.read_excel(r'C:\\Users\\MKK_Forschung\\Documents\\trend_pulse_data\\Test_data.xlsx')\n",
    "# main_dir = r'C:\\Users\\Data_Science\\Desktop\\trend_pulse_data'\n",
    "# experiment = 'Exp_6'\n",
    "# exp_dir = os.path.join(main_dir, experiment)\n",
    "# weights_dir = os.path.join(exp_dir, 'model_weights')\n",
    "# log_path = os.path.join(exp_dir, 'Training_log.txt')\n",
    "# os.makedirs(weights_dir, exist_ok=True)\n",
    "# Load the product encoding dictionary\n",
    "with open(os.path.join(exp_dir,'product_to_index.pkl'), 'rb') as f:\n",
    "    product_to_index = pickle.load(f)\n",
    "\n",
    "# Load the main category encoding dictionary\n",
    "with open(os.path.join(exp_dir,'main_category_to_index.pkl'), 'rb') as f:\n",
    "    main_category_to_index = pickle.load(f)\n",
    "\n",
    "# Load the subcategory encoding dictionary\n",
    "with open(os.path.join(exp_dir,'sub_category_to_index.pkl'), 'rb') as f:\n",
    "    sub_category_to_index = pickle.load(f)\n",
    "# Step 1: Use ecoding Mappings to encode the test data\n",
    "# Encode the products using the loaded dictionary\n",
    "test_df['encoded_product'] = test_df['product'].map(product_to_index)\n",
    "\n",
    "# Encode the main categories using the loaded dictionary\n",
    "test_df['encoded_main_category'] = test_df['main_category'].map(main_category_to_index)\n",
    "\n",
    "# Encode the subcategories using the loaded dictionary\n",
    "test_df['encoded_sub_category'] = test_df['sub_category'].map(sub_category_to_index)\n",
    "\n",
    "# Handle any potential missing values (e.g., if a test category is not found in the dictionary)\n",
    "# You can either fill with a default value or handle them as necessary.\n",
    "test_df['encoded_product'] = test_df['encoded_product'].fillna(-1).astype(int)\n",
    "test_df['encoded_main_category'] = test_df['encoded_main_category'].fillna(-1).astype(int)\n",
    "test_df['encoded_sub_category'] = test_df['encoded_sub_category'].fillna(-1).astype(int)\n",
    "\n",
    "\n",
    "# Create the int_rating column using a lambda function with three categories of ratings\n",
    "test_df['int_rating'] = test_df['ratings'].apply(lambda x: 0 if x <= 2.5 else (1 if x <= 4.0 else 2))\n",
    "\n",
    "\n",
    "# Convert prices from rupees to USD\n",
    "test_df['actual_price'] = test_df['actual_price'] / 83\n",
    "test_df['discount_price'] = test_df['discount_price'] / 83\n",
    "\n",
    "# Optional: Process the 'link' column if necessary or drop it\n",
    "# df = train_df.drop(columns=['link'])\n",
    "\n",
    "# Step 2: Normalize numerical columns\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical features\n",
    "test_df[['ratings', 'no_of_ratings', 'actual_price', 'discount_price']] = scaler.fit_transform(test_df[['ratings', 'no_of_ratings', 'actual_price', 'discount_price']])\n",
    "\n",
    "import torch\n",
    "\n",
    "# Convert training data to PyTorch tensors\n",
    "test_product_ids = torch.tensor(test_df['encoded_product'].values, dtype=torch.long)\n",
    "test_category_ids = torch.tensor(test_df['encoded_main_category'].values, dtype=torch.long)\n",
    "test_subcategory_ids = torch.tensor(test_df['encoded_sub_category'].values, dtype=torch.long)\n",
    "test_ratings = torch.tensor(test_df['ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "test_no_of_ratings = torch.tensor(test_df['no_of_ratings'].values, dtype=torch.float32).view(-1, 1)\n",
    "test_actual_price = torch.tensor(test_df['actual_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "test_discount_price = torch.tensor(test_df['discount_price'].values, dtype=torch.float32).view(-1, 1)\n",
    "test_labels = torch.tensor(test_df['int_rating'].values, dtype=torch.long)  # CrossEntropyLoss expects long dtype for labels\n",
    "\n",
    "# Combine tensors into TensorDatasets\n",
    "# test_dataset = TensorDataset(test_product_ids, test_category_ids, test_subcategory_ids, test_ratings, test_no_of_ratings, test_actual_price, test_discount_price, test_labels)\n",
    "test_dataset = TensorDataset(test_category_ids, test_subcategory_ids, test_ratings, test_no_of_ratings, test_actual_price, test_discount_price, test_labels)\n",
    "\n",
    "# Create DataLoaders for batching\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize metrics trackers\n",
    "def compute_accuracy(predictions, labels):\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    return accuracy_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
    "\n",
    "def compute_auc(predictions, labels, num_classes):\n",
    "    predictions_prob = F.softmax(predictions, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    if num_classes == 2:\n",
    "        return roc_auc_score(labels, predictions_prob[:, 1])  # For binary classification\n",
    "    else:\n",
    "        return roc_auc_score(labels, predictions_prob, multi_class='ovr')  # For multi-class classification\n",
    "    \n",
    "def logging(log_path, log_text):\n",
    "    with open(log_path, 'a') as file:\n",
    "        file.write(log_text + '\\n')\n",
    "        \n",
    "        \n",
    "# Function to calculate and plot AUC-ROC\n",
    "def calculate_and_plot_average_auc_roc(test_labels, test_probs, num_classes):\n",
    "    # Binarize the labels for all classes\n",
    "    true_labels_one_hot = np.eye(num_classes)[test_labels]\n",
    "    \n",
    "    # Calculate the micro-average ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(true_labels_one_hot.ravel(), test_probs.ravel())\n",
    "    average_auc = roc_auc_score(true_labels_one_hot, test_probs, average='micro')\n",
    "\n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Average AUC (micro) = {average_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Average ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    return average_auc\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(test_labels, test_preds, class_names):\n",
    "    \"\"\"\n",
    "    Plots the confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "    - test_labels: True labels for the test data.\n",
    "    - test_preds: Predicted labels for the test data.\n",
    "    - class_names: List of class names.\n",
    "    \"\"\"\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plot_precision_f1(test_probs, test_labels, num_classes=3):\n",
    "    \"\"\"\n",
    "    Function to calculate and plot precision and F1 score for each class.\n",
    "    \n",
    "    Args:\n",
    "        test_probs (torch.Tensor): The predicted probabilities from the model.\n",
    "        test_labels (torch.Tensor): The true labels.\n",
    "        num_classes (int): Number of classes in the classification task.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    probs_np = test_probs\n",
    "    labels_np = test_labels\n",
    "\n",
    "    # Get the predicted class by finding the class with the maximum probability\n",
    "    preds = probs_np.argmax(axis=1)\n",
    "\n",
    "    # Calculate precision and F1 score for each class\n",
    "    precision_per_class = precision_score(labels_np, preds, average=None, labels=range(num_classes))\n",
    "    f1_per_class = f1_score(labels_np, preds, average=None, labels=range(num_classes))\n",
    "\n",
    "    # Define class names\n",
    "    classes = [f'Class {i}' for i in range(num_classes)]\n",
    "\n",
    "    # Plotting the Precision\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(classes, precision_per_class, color='blue')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('Precision per Class')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Precision')\n",
    "\n",
    "    # Plotting the F1 Score\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(classes, f1_per_class, color='green')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('F1 Score per Class')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('F1 Score')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_multiclass_roc(y_true, y_pred, n_classes=3):\n",
    "    # Binarize the output\n",
    "    y_true_bin = label_binarize(y_true, classes=[*range(n_classes)])\n",
    "    y_pred_bin = label_binarize(y_pred, classes=[*range(n_classes)])\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_bin[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for Multiclass Classification')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RecommendationModel(\n",
    "#   (product_embedding): Embedding(28588, 10)\n",
    "#   (category_embedding): Embedding(10, 5)\n",
    "#   (subcategory_embedding): Embedding(12, 5)\n",
    "#   (fc1): Linear(in_features=24, out_features=64, bias=True)\n",
    "#   (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
    "#   (fc3): Linear(in_features=32, out_features=3, bias=True)\n",
    "# )\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "# num_products = 28588    # len(df['encoded_product'].unique())\n",
    "num_categories = 10     # len(df['encoded_main_category'].unique())\n",
    "num_subcategories = 12  #  len(df['encoded_sub_category'].unique())\n",
    "\n",
    "# model = RecommendationModel(num_products, num_categories, num_subcategories)\n",
    "model = RecommendationModel(num_categories, num_subcategories, embedding_dim=10)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(weights_dir, 'best_model.pth')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Final Test Metrics:\n",
      "\n",
      "Accuracy: 0.9997\n",
      "Precision: 0.9997\n",
      "Recall: 0.9997\n",
      "F1 Score: 0.9997\n",
      "Confusion Matrix:\n",
      "[[ 351    2    0]\n",
      " [   0 3695    0]\n",
      " [   0    0 3362]]\n",
      "Testing Complete !!!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "\n",
    "model = model.to(device)  # Move model to the appropriate device\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Initialize lists to store probabilities and labels\n",
    "test_probs = []\n",
    "test_preds = []\n",
    "test_labels = []\n",
    "\n",
    "# Testing loop\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for batch in test_loader:\n",
    "        # Unpack batch data\n",
    "        # product_id, category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "        category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price, labels = batch\n",
    "        \n",
    "        # Move data to the appropriate device\n",
    "        # product_id, category_id, subcategory_id = product_id.to(device), category_id.to(device), subcategory_id.to(device)\n",
    "        category_id, subcategory_id = category_id.to(device), subcategory_id.to(device)\n",
    "\n",
    "        ratings, no_of_ratings = ratings.to(device), no_of_ratings.to(device)\n",
    "        actual_price, discount_price = actual_price.to(device), discount_price.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        # outputs = model(product_id, category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price)\n",
    "        outputs = model(category_id, subcategory_id, ratings, no_of_ratings, actual_price, discount_price)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        preds = probs.argmax(dim=1)\n",
    "        \n",
    "        # Store probabilities, predictions, and labels\n",
    "        test_probs.append(probs.cpu())\n",
    "        test_preds.append(preds.cpu())\n",
    "        test_labels.append(labels.cpu())\n",
    "\n",
    "# Concatenate results across all batches\n",
    "test_probs = torch.cat(test_probs)\n",
    "test_preds = torch.cat(test_preds)\n",
    "test_labels = torch.cat(test_labels)\n",
    "\n",
    "# Convert to numpy arrays for metrics calculation and saving\n",
    "test_probs_np = test_probs.numpy()\n",
    "test_preds_np = test_preds.numpy()\n",
    "test_labels_np = test_labels.numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels_np, test_preds_np)\n",
    "precision = precision_score(test_labels_np, test_preds_np, average='weighted')\n",
    "recall = recall_score(test_labels_np, test_preds_np, average='weighted')\n",
    "f1 = f1_score(test_labels_np, test_preds_np, average='weighted')\n",
    "conf_matrix = confusion_matrix(test_labels_np, test_preds_np)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Final Test Metrics:\\n')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "test_prob_df = pd.DataFrame(test_probs_np, columns=[f'prob_class_{i}' for i in range(test_probs_np.shape[1])])\n",
    "test_prob_df['predictions'] = test_preds_np\n",
    "test_prob_df['labels'] = test_labels_np\n",
    "\n",
    "# Save the results to an Excel file\n",
    "test_prob_df.to_excel(os.path.join(exp_dir, 'test_data_predictions.xlsx'), index=False)\n",
    "\n",
    "print('Testing Complete !!!')\n",
    "\n",
    "# Calculate the AUC for all classes and plot ROC curves\n",
    "num_classes = test_probs_np.shape[1]\n",
    "# average_auc = calculate_and_plot_average_auc_roc(test_labels_np, test_probs_np, num_classes)\n",
    "# print(f'Average AUC: {average_auc:.4f}')\n",
    "\n",
    "# Print the average AUC\n",
    "# print(f'Average AUC: {average_auc:.4f}')\n",
    "\n",
    "plot_precision_f1(test_probs_np, test_labels_np, num_classes=3)\n",
    "\n",
    "class_names = [f'Class {i}' for i in range(num_classes)]\n",
    "\n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(test_labels_np, test_preds_np, class_names)\n",
    "\n",
    "plot_multiclass_roc(test_labels_np, test_preds_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regular_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
